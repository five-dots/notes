#+STARTUP: folded indent
#+PROPERTY: header-args:R :results output :colnames yes :session *R:mlr3*

* ={mlr3}=
* ライブラリの読み込み
  
#+begin_src R :results silent
library(tidyverse)

library(mlr3)
library(mlr3learners)
library(mlr3pipelines)
library(mlr3tuning)
library(mlr3filters)
library(mlr3viz)

library(paradox)
#+end_src

* 全関数 ={mlr3}=

#+begin_src R
pacman::p_funs(mlr3)
#+end_src

#+RESULTS:
#+begin_example
 [1] "as_benchmark_result"       "as_data_backend"          
 [3] "as_learner"                "as_learners"              
 [5] "as_measure"                "as_measures"              
 [7] "as_resampling"             "as_resamplings"           
 [9] "as_task"                   "as_tasks"                 
[11] "as.data.table"             "assert_backend"           
[13] "assert_benchmark_result"   "assert_learner"           
[15] "assert_learners"           "assert_measure"           
[17] "assert_measures"           "assert_prediction"        
[19] "assert_resample_result"    "assert_resampling"        
[21] "assert_resamplings"        "assert_row_ids"           
[23] "assert_task"               "assert_tasks"             
[25] "benchmark"                 "benchmark_grid"           
[27] "BenchmarkResult"           "confusion_measures"       
[29] "DataBackend"               "DataBackendDataTable"     
[31] "DataBackendMatrix"         "default_measures"         
[33] "Learner"                   "LearnerClassif"           
[35] "LearnerClassifDebug"       "LearnerClassifFeatureless"
[37] "LearnerClassifRpart"       "LearnerRegr"              
[39] "LearnerRegrFeatureless"    "LearnerRegrRpart"         
[41] "lrn"                       "lrns"                     
[43] "Measure"                   "MeasureClassif"           
[45] "MeasureClassifACC"         "MeasureClassifAUC"        
[47] "MeasureClassifCE"          "MeasureClassifConfusion"  
[49] "MeasureClassifCosts"       "MeasureClassifFScore"     
[51] "MeasureDebug"              "MeasureElapsedTime"       
[53] "MeasureOOBError"           "MeasureRegr"              
[55] "MeasureRegrMAE"            "MeasureRegrMSE"           
[57] "MeasureRegrRMSE"           "MeasureSelectedFeatures"  
[59] "mlr_learners"              "mlr_measures"             
[61] "mlr_reflections"           "mlr_resamplings"          
[63] "mlr_task_generators"       "mlr_tasks"                
[65] "msr"                       "msrs"                     
[67] "Prediction"                "PredictionClassif"        
[69] "PredictionRegr"            "resample"                 
[71] "ResampleResult"            "Resampling"               
[73] "ResamplingBootstrap"       "ResamplingCustom"         
[75] "ResamplingCV"              "ResamplingHoldout"        
[77] "ResamplingRepeatedCV"      "ResamplingSubsampling"    
[79] "rsmp"                      "rsmps"                    
[81] "Task"                      "TaskClassif"              
[83] "TaskGenerator"             "TaskGenerator2DNormals"   
[85] "TaskGeneratorFriedman1"    "TaskGeneratorSmiley"      
[87] "TaskGeneratorXor"          "TaskRegr"                 
[89] "TaskSupervised"            "tgen"                     
[91] "tgens"                     "tsk"                      
[93] "tsks"
#+end_example

* 主要 5 クラス
** Task (タスクの定義と目的変数 + 特徴量の指定)
*** 概要

- Pre-defined されたタスク
#+begin_src R
mlr_tasks
#+end_src

#+RESULTS:
: <
: with 9 stored values
: Keys: boston_housing, german_credit, iris, mtcars, pima, sonar, spam,
:   wine, zoo

- Task を抽出する
#+begin_src R
tsk("iris")
#+end_src

#+RESULTS:
: <TaskClassif:
: (150 x 5)
: * Target: Species
: * Properties: multiclass
: * Features (4):
:   - dbl (4): Petal.Length, Petal.Width, Sepal.Length, Sepal.Width

*** =Task= (抽象クラス)
**** --- Contructor ---
**** =new(id, task_type, backend)=

#+begin_src R :results silent
task_iris <- Task$new(id = "iris", task_type = "classif", backend = iris)
#+end_src

- 選択可能なタスク
#+begin_src R
mlr_reflections$task_types$type
#+end_src

#+RESULTS:
: [1] "classif" "regr"

**** --- Properties ---
**** =id=, =hash=, =ncol=, =nrow=, =task_type=

#+begin_src R
task_iris$id
#+end_src

#+RESULTS:
: [1] "iris"

#+begin_src R
task_iris$hash
#+end_src

#+RESULTS:
: [1] "96b3c81da6869e5c"

#+begin_src R
task_iris$ncol
#+end_src

#+RESULTS:
: [1] 5

#+begin_src R
task_iris$nrow
#+end_src

#+RESULTS:
: [1] 150

#+begin_src R
task_iris$task_type
#+end_src

#+RESULTS:
: [1] "classif"

**** =col_info=, =col_roles=

#+begin_src R
task_iris$col_info
#+end_src

#+RESULTS:
:              id    type                      levels
: 1:     ..row_id integer                            
: 2: Petal.Length numeric                            
: 3:  Petal.Width numeric                            
: 4: Sepal.Length numeric                            
: 5:  Sepal.Width numeric                            
: 6:      Species  factor setosa,versicolor,virginica

#+begin_src R
task_iris$col_roles
#+end_src

#+RESULTS:
#+begin_example
$feature
[1] "Petal.Length" "Petal.Width"  "Sepal.Length" "Sepal.Width"  "Species"     

$target
character(0)

$name
character(0)

$order
character(0)

$stratify
character(0)

$groups
character(0)

$weights
character(0)
#+end_example

**** =row_roles=, =row_ids=

#+begin_src R
task_iris$row_roles
#+end_src

#+RESULTS:
#+begin_example
$use
  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
 [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
 [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
 [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72
 [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
 [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108
[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
[145] 145 146 147 148 149 150

$validation
integer(0)
#+end_example

#+begin_src R
task_iris$row_ids
#+end_src

#+RESULTS:
:   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
:  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
:  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
:  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72
:  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
:  [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108
: [109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
: [127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
: [145] 145 146 147 148 149 150

**** =feature_names=, =feature_types=, =target_names=

#+begin_src R
task_iris$feature_names
#+end_src

#+RESULTS:
: [1] "Petal.Length" "Petal.Width"  "Sepal.Length" "Sepal.Width"

#+begin_src R
task_iris$feature_types
#+end_src

#+RESULTS:
:              id    type
: 1: Petal.Length numeric
: 2:  Petal.Width numeric
: 3: Sepal.Length numeric
: 4:  Sepal.Width numeric

#+begin_src R
task_iris$target_names
#+end_src

#+RESULTS:
: character(0)

**** =properties=

#+begin_src R
task_iris$properties
#+end_src

#+RESULTS:
: [1] "multiclass"

- Possible properties
#+begin_src R
mlr_reflections$task_properties
#+end_src

#+RESULTS:
: $classif
: [1] "stratify"   "groups"     "weights"    "twoclass"   "multiclass"
: 
: $regr
: [1] "stratify" "groups"   "weights"

**** --- Methods ---
**** =data(rows = NULL, cols = NULL, data_format = NULL)=

#+begin_src R
task_iris$data(row = 1:5)
#+end_src

#+RESULTS:
:    Species Petal.Length Petal.Width Sepal.Length Sepal.Width
: 1:  setosa          1.4         0.2          5.1         3.5
: 2:  setosa          1.4         0.2          4.9         3.0
: 3:  setosa          1.3         0.2          4.7         3.2
: 4:  setosa          1.5         0.2          4.6         3.1
: 5:  setosa          1.4         0.2          5.0         3.6

**** =formula(rhs = ".")=

#+begin_src R
task_iris$formula()
#+end_src

#+RESULTS:
: Species ~ .
: NULL

**** =levels(cols = NULL)=

#+begin_src R
task_iris$levels()
#+end_src

#+RESULTS:
: $Species
: [1] "setosa"     "versicolor" "virginica"

**** =droplevels(cols = NULL)=

- 現在のデータセットに含まれていない因子を削除する
#+begin_src R
task_iris$droplevels()
#+end_src

#+RESULTS:

**** =missings(cols = NULL)=

- 欠損値を表示
#+begin_src R
task_iris$missings(cols = NULL)
#+end_src

#+RESULTS:
:      Species Petal.Length  Petal.Width Sepal.Length  Sepal.Width 
:            0            0            0            0            0

**** =head(n = 6)=

#+begin_src R
task_iris$head()
#+end_src

#+RESULTS:
:    Species Petal.Length Petal.Width Sepal.Length Sepal.Width
: 1:  setosa          1.4         0.2          5.1         3.5
: 2:  setosa          1.4         0.2          4.9         3.0
: 3:  setosa          1.3         0.2          4.7         3.2
: 4:  setosa          1.5         0.2          4.6         3.1
: 5:  setosa          1.4         0.2          5.0         3.6
: 6:  setosa          1.7         0.4          5.4         3.9

**** =filter(rows)=, =select(cols)=, =cbind(data)=, =rbind(data)=, =rename(from, to)=
**** =help()=
*** =TaskSupervised= (抽象クラス + Task)
**** =truth(rows = NULL)=

- 教師有り学習の正解データ

#+begin_src R
task_iris$truth()
#+end_src

#+RESULTS:
#+begin_example
  [1] setosa     setosa     setosa     setosa     setosa     setosa    
  [7] setosa     setosa     setosa     setosa     setosa     setosa    
 [13] setosa     setosa     setosa     setosa     setosa     setosa    
 [19] setosa     setosa     setosa     setosa     setosa     setosa    
 [25] setosa     setosa     setosa     setosa     setosa     setosa    
 [31] setosa     setosa     setosa     setosa     setosa     setosa    
 [37] setosa     setosa     setosa     setosa     setosa     setosa    
 [43] setosa     setosa     setosa     setosa     setosa     setosa    
 [49] setosa     setosa     versicolor versicolor versicolor versicolor
 [55] versicolor versicolor versicolor versicolor versicolor versicolor
 [61] versicolor versicolor versicolor versicolor versicolor versicolor
 [67] versicolor versicolor versicolor versicolor versicolor versicolor
 [73] versicolor versicolor versicolor versicolor versicolor versicolor
 [79] versicolor versicolor versicolor versicolor versicolor versicolor
 [85] versicolor versicolor versicolor versicolor versicolor versicolor
 [91] versicolor versicolor versicolor versicolor versicolor versicolor
 [97] versicolor versicolor versicolor versicolor virginica  virginica 
[103] virginica  virginica  virginica  virginica  virginica  virginica 
[109] virginica  virginica  virginica  virginica  virginica  virginica 
[115] virginica  virginica  virginica  virginica  virginica  virginica 
[121] virginica  virginica  virginica  virginica  virginica  virginica 
[127] virginica  virginica  virginica  virginica  virginica  virginica 
[133] virginica  virginica  virginica  virginica  virginica  virginica 
[139] virginica  virginica  virginica  virginica  virginica  virginica 
[145] virginica  virginica  virginica  virginica  virginica  virginica 
Levels: setosa versicolor virginica
#+end_example

*** =TaskClassif= (Task + TaskSupervised)
**** =new(id, backend, target, positive = NULL)=

- 二値分類 or マルチラベル分類
#+begin_src R :results silent
TaskClassif$new(
  id,
  backend,
  target, # 目的変数のカラム名 (因子型)
  positive = NULL # 2値分類タスクの場合の正の因子
)
#+end_src

**** =class_names=

#+begin_src R
task_iris$class_names
#+end_src

#+RESULTS:
: [1] "setosa"     "versicolor" "virginica"

**** =positive=, =negative=

#+begin_src R
task_iris$positive
task_iris$negative
#+end_src

#+RESULTS:
: [1] NA
: [1] NA

*** =TaskRegr= (Task + TaskSupervised)
**** =new(id, backend, target)=

- 回帰問題
#+begin_src R :results silent
TaskRegr$new(
  id,
  backend,
  target # 目的変数のカラム名 (因子型)
)
#+end_src

#+begin_src R
t_iris_regr <- TaskRegr$new(id = "iris", backend = iris, target = "Sepal.Width")
t_iris_regr
#+end_src

#+RESULTS:
: 
: 
: 
: Features:
: NULL

** Learner (学習器(モデル)の選択・パラメタ設定・学習・予測)
*** 概要

- ={mlr3}= にほそれほど多くのモデルは含まれていない
- ={mlr3learners}= を追加すると xgboost なども利用可能になる
- その他にも、拡張パッケージが存在する
#+begin_src R
library(mlr3learners)
mlr_learners
#+end_src

#+RESULTS:
: <
: with 21 stored values
: Keys: classif.debug, classif.featureless, classif.glmnet, classif.kknn,
:   classif.lda, classif.log_reg, classif.naive_bayes, classif.qda,
:   classif.ranger, classif.rpart, classif.svm, classif.xgboost,
:   regr.featureless, regr.glmnet, regr.kknn, regr.km, regr.lm,
:   regr.ranger, regr.rpart, regr.svm, regr.xgboost

- =lrn()= で抽出
#+begin_src R
lrn("classif.xgboost")
#+end_src

#+RESULTS:
: <LearnerClassifXgboost:classif.xgboost>
: * Model: -
: * Parameters: nrounds=1, verbose=0
: * Packages: xgboost
: * Predict Type: response
: * Feature types: integer, numeric
: * Properties: importance, missings, multiclass, twoclass, weights

*** =Learner= (抽象クラス)
**** --- Properties ---
**** =id=
Identifier of the learner.
**** =task_type=

Stores the type of class this learner can operate on, e.g. "classif" or "regr". A complete list of task types is stored in mlr_reflections$task_types.

**** =param_set=

Description of available hyperparameters and hyperparameter settings.

**** =predict_types=

Stores the possible predict types the learner is capable of. A complete list of candidate predict types, grouped by task type, is stored in mlr_reflections$learner_predict_types.

**** =predict_type=

Stores the currently selected predict type. Must be an element of l$predict_types.

**** =feature_types=

Stores the feature types the learner can handle, e.g. "logical", "numeric", or "factor". A complete list of candidate feature types, grouped by task type, is stored in mlr_reflections$task_feature_types.

**** =properties=

Stores a set of properties/capabilities the learner has. A complete list of candidate properties, grouped by task type, is stored in mlr_reflections$learner_properties.

**** =packages=

Stores the names of required packages.

**** =state=

Current (internal) state of the learner. Contains all information learnt during train() and predict(). It is not recommended to access elements from state directly, this is an internal data structure which may change in the future.

**** =encapsulate=

How to call the code in train_internal() and predict_internal(). Must be a named character vector with names "train" and "predict". Possible values are "none", "evaluate" and "callr". See mlr3misc::encapsulate() for more details.

**** =fallback=

Learner which is fitted to impute predictions in case that either the model fitting or the prediction of the top learner is not successful. Requires you to enable encapsulation, otherwise errors are not caught and the execution is terminated before the fallback learner kicks in.

**** =hash=

Hash (unique identifier) for this object.

**** =model=

The fitted model. Only available after $train() has been called.

**** =timings=

Elapsed time in seconds for the steps "train" and "predict". Measured via mlr3misc::encapsulate().

**** =log=

Returns the output (including warning and errors) as table with columns "stage" (train or predict), "class" (output, warning, error) and "msg" (character()).

**** =warnings=

Returns the logged warnings as vector.

**** =errors=

Returns the logged errors as vector.

**** --- Methods ---
**** =train(task, row_ids = NULL))=

- =row_ids= で学習データを指定

**** =predict(task, row_ids = NULL)=

- =row_ids= でテストデータを指定 

**** =predict_newdata(newdata, task = NULL)=
**** =reset()=
**** =help()=
*** =LearnerClassif=

#+begin_src R :results silent
LearnerClassif$new(
  id, # 名前
  param_set = ParamSet$new(), # ハイパーパラメタ by paradox::ParamSet
  predict_types = character(), # "response"(ラベル) or "prob"(確率)
  feature_types = character(),
  properties = character(),
  data_formats = "data.table",
  packages = character(),
  man = NA_character_
)
#+end_src

*** =LearnerRegr=

#+begin_src R
LearnerRegr$new(
  id,
  param_set = ParamSet$new(),
  predict_types = character(),
  feature_types = character(),
  properties = character(),
  data_formats = "data.table",
  packages = character(),
  man = NA_character_)
#+end_src

** Measure (予測結果のスコアを算出)
*** 概要

- =Prediction$score()= 関数に渡して使う
- ={mlr3measures}= に収録されている
#+begin_src R
mlr_measures
#+end_src

#+RESULTS:
#+begin_example
<
with 51 stored values
Keys: classif.acc, classif.auc, classif.bacc, classif.ce,
  classif.costs, classif.dor, classif.fbeta, classif.fdr, classif.fn,
  classif.fnr, classif.fomr, classif.fp, classif.fpr, classif.logloss,
  classif.mcc, classif.npv, classif.ppv, classif.precision,
  classif.recall, classif.sensitivity, classif.specificity, classif.tn,
  classif.tnr, classif.tp, classif.tpr, debug, oob_error, regr.bias,
  regr.ktau, regr.mae, regr.mape, regr.maxae, regr.medae, regr.medse,
  regr.mse, regr.msle, regr.pbias, regr.rae, regr.rmse, regr.rmsle,
  regr.rrse, regr.rse, regr.rsq, regr.sae, regr.smape, regr.srho,
  regr.sse, selected_features, time_both, time_predict, time_train
#+end_example

#+begin_src R
msr("classif.acc")
#+end_src

#+RESULTS:
: <MeasureClassifSimple:classif.acc>
: * Packages: mlr3measures
: * Range: [0, 1]
: * Minimize: FALSE
: * Properties: -
: * Predict type: response

*** Measure
**** コンストラクタ

- 実際に自分でクラスを作成することは少なそう
- =msr()= で既存のものを利用する
#+begin_src R
Measure$new(
  id,
  task_type = NA,
  range = c(-Inf, Inf),
  minimize = NA, average = "macro",
  aggregator = NULL,
  properties = character(),
  predict_type = "response",
  predict_sets = "test",
  task_properties = character(),
  packages = character(),
  man = NA_character_
)
#+end_src

#+begin_src R
m <- msr("classif.acc")
class(m)
#+end_src

#+RESULTS:
: [1] "MeasureClassifSimple" "MeasureClassif"       "Measure"             
: [4] "R6"

- 平均の算出方法
#+begin_src R
m$average # macro or micro
m$aggregator # micro の場合ここで関数を指定する
#+end_src

#+RESULTS:
: [1] "macro"
: NULL

**** --- Methods---
**** =aggregate(rr)=

- ResampleResult を渡して CV スコアを算出する

**** =score(prediction, task = NULL, learner = NULL, train_set = NULL)=

- Prediction, Task, Learner のクラスをそれぞれ渡してスコアを算出する

** Resampling
*** 概要

- *6 つの戦略を実装*
  1. Cross-validation
  2. Leave-one-out cross validation (LOO)
  3. Repeated cross-validation
  4. Out-of-bag bootstrap and other variants (e.g. b632)
  5. Monte-Carlo cross-validation
  6. Holdout

- Bootstrap sampling = 母集団から重複を許してランダムにサンプリングする
- 層化抽出・グルーピング
  - Task 自体に strata, group を設定することで可能になる

#+begin_src R
mlr_resamplings

cv <- rsmp("cv", folds = 4) # ... でコンストラクタのパラメタを設定可能
cv
#+end_src

#+RESULTS:
: <
: with 6 stored values
: Keys: bootstrap, custom, cv, holdout, repeated_cv, subsampling
: <
: with 4 iterations
: * Instantiated: FALSE
: * Parameters: folds=4

#+begin_src R
r$instantiate(t)
r$train_set(1) # 1番目の学習データ
r$test_set(1)  # 1番目のテストデータ
#+end_src

#+RESULTS:
:   [1]   3   4   8   9  11  16  17  18  25  27  29  32  35  43  47  48  54  56
:  [19]  58  59  64  71  74  76  85  90  97  98 100 113 116 119 127 128 131 132
:  [37] 144 145   1  13  15  24  26  30  31  37  42  49  52  55  68  70  72  77
:  [55]  82  84  89  91  96  99 101 107 111 112 117 118 126 133 135 139 141 143
:  [73] 148 149 150   2   6   7  10  12  14  19  20  21  33  40  44  45  46  50
:  [91]  57  60  61  63  65  75  78  83  88  95 103 104 106 115 121 123 124 129
: [109] 134 136 138 140
:  [1]   5  22  23  28  34  36  38  39  41  51  53  62  66  67  69  73  79  80  81
: [20]  86  87  92  93  94 102 105 108 109 110 114 120 122 125 130 137 142 146 147

*** =Resampling=

#+begin_src R
Resampling$new(
  id,
  param_set,
  duplicated_ids = FALSE,
  man = NA_character_)
#+end_src

** Prediction (モデルの予測データと評価)
*** 概要

- =Learner$predict(Task, row_ids)= から作成される
- 予測スコアの算出 (以下のどちらでも予測スコアを算出できる)
  - =Prediction$score(measures = NULL, task = NULL, learner = NULL)=
  - =Measure$score(prediction, task = NULL, learner = NULL, train_set = NULL)=

#+begin_src R
t <- tsk("iris")
l <- lrn("classif.rpart")
l$train(t, row_ids = 1:120)
p <- l$predict(t, row_ids = 121:150)
class(p)
#+end_src

#+RESULTS:
: [1] "PredictionClassif" "Prediction"        "R6"

- Accuracy を算出
#+begin_src R
m <- msr("classif.acc")
m$score(p)
#+end_src

#+RESULTS:
: [1] 0.8333333

#+begin_src R
p$row_ids  # 予測した行
p$response # 予測値. p$prob の場合もある
p$truth    # 正解データ
#+end_src

#+RESULTS:
#+begin_example
 [1] 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
[20] 140 141 142 143 144 145 146 147 148 149 150
 [1] virginica  versicolor virginica  versicolor virginica  virginica 
 [7] versicolor versicolor virginica  virginica  virginica  virginica 
[13] virginica  virginica  virginica  virginica  virginica  virginica 
[19] versicolor virginica  virginica  virginica  virginica  virginica 
[25] virginica  virginica  virginica  virginica  virginica  virginica 
Levels: setosa versicolor virginica
 [1] virginica virginica virginica virginica virginica virginica virginica
 [8] virginica virginica virginica virginica virginica virginica virginica
[15] virginica virginica virginica virginica virginica virginica virginica
[22] virginica virginica virginica virginica virginica virginica virginica
[29] virginica virginica
Levels: setosa versicolor virginica
#+end_example

- 混同行列
#+begin_src R
p$confusion
#+end_src

#+RESULTS:
:             truth
: response     setosa versicolor virginica
:   setosa          0          0         0
:   versicolor      0          0         5
:   virginica       0          0        25

* 関数解説
** =resample(task, learner, resampling, store_models = FALSE)=

- Task, Learner, Resampling を組み合わせてバリデーションを実行する

** =benchmark_grid(tasks, learners, resamplings)=

- =benchmark()= に渡すグリッドを作成する

** =benchmark(design, store_models = FALSE)=

- 複数の Task, Learner, Resampling を組み合わせてパフォーマンスを評価する

* 公式サイトの Example

- iris の Species を目的変数
- ={rpart}= を使う
#+begin_src R
task_iris <- TaskClassif$new(id = "iris", backend = iris, target = "Species")
task_iris

learner <- lrn("classif.rpart", cp = 0.01)
learner

## train/test split
train_set <- sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set <- setdiff(seq_len(task_iris$nrow), train_set)

## train the model
learner$train(task_iris, row_ids = train_set)

## predict data
prediction <- learner$predict(task_iris, row_ids = test_set)

## calculate performance
prediction$confusion

measure <- msr("classif.acc")
prediction$score(measure)
#+end_src

#+RESULTS:
#+begin_example



Features:
NULL

Learner classif.rpart from package 
Type: 
Name: ; Short name: 
Class: LearnerClassifRpart
Properties: importance,missings,multiclass,selected_features,twoclass,weights
Predict-Type: 
Hyperparameters:

            truth
response     setosa versicolor virginica
  setosa          9          0         0
  versicolor      0         14         1
  virginica       0          0         6

classif.acc 
  0.9666667
#+end_example

* 拡張パッケージ
** 概要

- ={mlr3pipeline}= 前処理
- ={mlr3learners}= モデル
- ={mlr3tuning}=   パラメタチューニング
- ={mlr3measures}= 評価指標
- ={mlr3viz}=      可視化

その他
- ={mlr3spatiotemporal}= Spatial data

** パイプライン by ={mlr3pipelines}=
*** 概要

- ={mlr3pipelines}= (={mlrCPO}= の後継)
- 主な機能
  1. データ操作・前処理・特徴量選択・欠損処理
  2. Task のサブサンプル作成 (高速化などが目的)
  3. Learner の操作と予測・スタッキング
  4. 予測結果のアンサンブル
- 個々の処理は *PipeOps (PO)* と呼ばれる
- list 形式で複数の入力・出力を PO 間でやり取りする
- 複数の PO をつなげて Graph を作成する
- Graph 自身にも =train()=, =predict()= を持っていて、Graph から出力を得ることができる
- ={mlr3}= との統合
  - =PipeOpsLearner= mlr3 の Learner を内包する PO
  - =GraphLearner= Learner として Graph を利用するクラス 
   - =resample()= や =benchmark()= の Learner として利用する

#+begin_src R
mlr_pipeops

po("learner", lrn("classif.rpart"))
#+end_src

#+RESULTS:
#+begin_example
<
with 42 stored values
Keys: boxcox, branch, chunk, classbalancing, classifavg, classweights,
  colapply, collapsefactors, copy, encode, encodeimpact, encodelmer,
  featureunion, filter, fixfactors, histbin, ica, imputehist,
  imputemean, imputemedian, imputenewlvl, imputesample, kernelpca,
  learner, learner_cv, missind, modelmatrix, mutate, nop, pca,
  quantilebin, regravg, removeconstants, scale, scalemaxabs,
  scalerange, select, smote, spatialsign, subsample, unbranch,
  yeojohnson
PipeOp: <
(not trained)
values: <xval=0>
Input channels <name [train type, predict type]>:
  input [TaskClassif,TaskClassif]
Output channels <name [train type, predict type]>:
  output [NULL,PredictionClassif]
#+end_example

*** PipeOps のリスト

- NA のところは innum / outnum で明示的に指定する
#+begin_src R :results value :rownames yes
as.data.table(mlr_pipeops)[, c("key", "input.num", "output.num")]
#+end_src

#+RESULTS:
|    | key             | input.num | output.num |
|----+-----------------+-----------+------------|
|  1 | boxcox          |         1 |          1 |
|  2 | branch          |         1 |        nil |
|  3 | chunk           |         1 |        nil |
|  4 | classbalancing  |         1 |          1 |
|  5 | classifavg      |       nil |          1 |
|  6 | classweights    |         1 |          1 |
|  7 | colapply        |         1 |          1 |
|  8 | collapsefactors |         1 |          1 |
|  9 | copy            |         1 |        nil |
| 10 | encode          |         1 |          1 |
| 11 | encodeimpact    |         1 |          1 |
| 12 | encodelmer      |         1 |          1 |
| 13 | featureunion    |       nil |          1 |
| 14 | filter          |         1 |          1 |
| 15 | fixfactors      |         1 |          1 |
| 16 | histbin         |         1 |          1 |
| 17 | ica             |         1 |          1 |
| 18 | imputehist      |         1 |          1 |
| 19 | imputemean      |         1 |          1 |
| 20 | imputemedian    |         1 |          1 |
| 21 | imputenewlvl    |         1 |          1 |
| 22 | imputesample    |         1 |          1 |
| 23 | kernelpca       |         1 |          1 |
| 24 | learner         |         1 |          1 |
| 25 | learner_cv      |         1 |          1 |
| 26 | missind         |         1 |          1 |
| 27 | modelmatrix     |         1 |          1 |
| 28 | mutate          |         1 |          1 |
| 29 | nop             |         1 |          1 |
| 30 | pca             |         1 |          1 |
| 31 | quantilebin     |         1 |          1 |
| 32 | regravg         |       nil |          1 |
| 33 | removeconstants |         1 |          1 |
| 34 | scale           |         1 |          1 |
| 35 | scalemaxabs     |         1 |          1 |
| 36 | scalerange      |         1 |          1 |
| 37 | select          |         1 |          1 |
| 38 | smote           |         1 |          1 |
| 39 | spatialsign     |         1 |          1 |
| 40 | subsample       |         1 |          1 |
| 41 | unbranch        |       nil |          1 |
| 42 | yeojohnson      |         1 |          1 |

*** PO + %>>%

- =%>>%= で PO をつないでいく
#+begin_src R
gr <- po("scale") %>>% po("pca")
gr
#+end_src

#+RESULTS:
: Graph with 2 PipeOps:
:     ID         State sccssors prdcssors
:  scale <<UNTRAINED>
:      pca          
:    pca <<UNTRAINED>
:              scale

#+begin_src R :results output graphics file :file (my/get-babel-file)
gr$plot()
#+end_src

#+RESULTS:
[[file:/home/shun/Dropbox/memo/img/babel/fig-wiDaGQ.png]]

*** PCA の例

- iris 分類タスクに PCA を適応してみる
- PO の重要コンポーネント
  - =train()=   list で引数を受取り、出力を list にして返す (結果を state に残す)
  - =state=     
  - =predict()= list で引数を受取り、出力を list にして返す (state の結果を利用する)
#+begin_src R
task <- tsk("iris")
pca <- po("pca")

pca$train(list(task))[[1]]$data()
pca$state

single_line_task <- task$clone()$filter(1)
pca$predict(list(single_line_task))[[1]]$data() # 上の1行目と同じ
#+end_src

#+RESULTS:
#+begin_example

       Species       PC1         PC2         PC3          PC4
  1:    setosa -2.684126  0.31939725 -0.02791483 -0.002262437
  2:    setosa -2.714142 -0.17700123 -0.21046427 -0.099026550
  3:    setosa -2.888991 -0.14494943  0.01790026 -0.019968390
  4:    setosa -2.745343 -0.31829898  0.03155937  0.075575817
  5:    setosa -2.728717  0.32675451  0.09007924  0.061258593
 ---                                                         
146: virginica  1.944110  0.18753230  0.17782509 -0.426195940
147: virginica  1.527167 -0.37531698 -0.12189817 -0.254367442
148: virginica  1.764346  0.07885885  0.13048163 -0.137001274
149: virginica  1.900942  0.11662796  0.72325156 -0.044595305
150: virginica  1.390189 -0.28266094  0.36290965  0.155038628

Standard deviations (1, .., p=4):
[1] 2.0562689 0.4926162 0.2796596 0.1543862

Rotation (n x k) = (4 x 4):
                     PC1         PC2         PC3        PC4
Petal.Length  0.85667061 -0.17337266  0.07623608  0.4798390
Petal.Width   0.35828920 -0.07548102  0.54583143 -0.7536574
Sepal.Length  0.36138659  0.65658877 -0.58202985 -0.3154872
Sepal.Width  -0.08452251  0.73016143  0.59791083  0.3197231

   Species       PC1       PC2         PC3          PC4
1:  setosa -2.684126 0.3193972 -0.02791483 -0.002262437
#+end_example

*** 特徴量結合の例

- "featureunion" は複数の入力 (list) を受取り =cbind()= して返す
- Input Channel を 2 つもつ場合
- Stacking などに利用できそう
#+begin_src R

## iris を2つに分割
iris_first_half = task$clone()$select(c("Petal.Length", "Petal.Width"))
iris_second_half = task$clone()$select(c("Sepal.Length", "Sepal.Width"))

## 再度結合する
po_fu <- po("featureunion", innum = 2)
po_fu$train(list(iris_first_half, iris_second_half))[[1]]$data()

## 入力が2つ
po_fu$input
#+end_src

#+RESULTS:
#+begin_example

       Species Petal.Length Petal.Width Sepal.Length Sepal.Width
  1:    setosa          1.4         0.2          5.1         3.5
  2:    setosa          1.4         0.2          4.9         3.0
  3:    setosa          1.3         0.2          4.7         3.2
  4:    setosa          1.5         0.2          4.6         3.1
  5:    setosa          1.4         0.2          5.0         3.6
 ---                                                            
146: virginica          5.2         2.3          6.7         3.0
147: virginica          5.0         1.9          6.3         2.5
148: virginica          5.2         2.0          6.5         3.0
149: virginica          5.4         2.3          6.2         3.4
150: virginica          5.1         1.8          5.9         3.0

     name train predict
1: input1  Task    Task
2: input2  Task    Task
#+end_example

*** グラフ実行の例

- iris をスケールしてから、10%をサンプリングする例
- Graph Class の =train()= にタスクを渡す
#+begin_src R
task <- tsk("iris")
gr <- po("scale") %>>% po("subsample", param_vals = list(frac = 0.1))
gr$train(task)[[1]]$data()
#+end_src

#+RESULTS:
#+begin_example

       Species Petal.Length Petal.Width Sepal.Length Sepal.Width
 1:     setosa  -1.33575163  -1.3110521   -1.7430170 -0.36096697
 2:     setosa  -1.56234224  -1.3110521   -1.5014904  1.24503015
 3:     setosa  -1.22245633  -1.3110521   -1.0184372 -0.13153881
 4:     setosa  -1.05251337  -1.0486668   -0.8976739  1.70388647
 5: versicolor   0.64691619   0.3944526    1.2760656  0.09788935
 6: versicolor   0.13708732   0.1320673   -0.4146207 -1.73753594
 7: versicolor   0.53362088   0.5256453    0.5514857  0.55674567
 8: versicolor   0.53362088   0.2632600    0.3099591 -0.36096697
 9: versicolor  -0.08950329   0.1320673   -0.2938574 -0.36096697
10: versicolor   0.36367793   0.2632600    0.9137757 -0.13153881
11: versicolor  -0.14615094  -0.2615107   -0.1730941 -1.04925145
12: versicolor  -0.42938920  -0.1303181   -0.8976739 -1.27867961
13:  virginica   1.32668801   1.7063794    1.6383555  1.24503015
14:  virginica   0.98680210   0.7880307    0.7930124 -0.13153881
15:  virginica   1.15674505   0.5256453    1.6383555 -0.13153881
#+end_example

** 特徴量選択 by ={mlr3filters}=

- ={mlr3filters}= の機能
- 主に 2 つのアルゴリズム
  - *Filter* Importance などから Rank を計算して重要な特徴量のみを利用
  - *Wrapper methods*

#+begin_src R
mlr_filters

flt("cmim")
#+end_src

#+RESULTS:
#+begin_example
<
with 16 stored values
Keys: anova, auc, carscore, cmim, correlation, disr, importance,
  information_gain, jmi, jmim, kruskal_test, mim, mrmr, njmim,
  performance, variance
<FilterCMIM:cmim>
Task Types: classif, regr
Task Properties: -
Packages: praznik
Feature types: integer, numeric, factor, ordered
#+end_example

- iris Task の特徴量ランク
#+begin_src R
filter <- FilterJMIM$new()
task <- tsk("iris")
filter$calculate(task)
as.data.table(filter)
#+end_src

#+RESULTS:
:         feature     score
: 1: Sepal.Length 1.0401337
: 2:  Petal.Width 0.9893676
: 3: Petal.Length 0.9880635
: 4:  Sepal.Width 0.8313703

- Learner のうち、importance を持つものは =FilterImportance= が使える
#+begin_src R
lrn <- lrn("classif.ranger", importance = "impurity")
task <- tsk("iris")
filter <- flt("importance", learner = lrn)
filter$calculate(task)
as.data.table(filter)
#+end_src

#+RESULTS:
:         feature     score
: 1: Petal.Length 44.419741
: 2:  Petal.Width 42.070551
: 3: Sepal.Length 10.328122
: 4:  Sepal.Width  2.391845

** パラメタチューニング by ={mlr3tuning}=
*** 概要

- ={mlr3tuning}= の機能
- チューニングの流れ
  1. 探索するパラメタを設定   (by =paradox::ParamSet$new()=)
  2. 最適化アルゴリズムを選択
  3. 評価指標を選択           (by =msr("hoge")=)

*** 0. パラメタ by ={paradox}=

- =Param= が抽象クラス
- =ParamDbl=, =ParamInt=, =ParamFct=, =ParamLgl=, =ParamUty= (Untyped) が具象クラス
- =ParamSet= で複数のパラメタを持つ

#+begin_src R
dbl_par <- ParamDbl$new("some_param", lower = 0, upper = 1, default = 0.5, tags = c("required"))
dbl_par

fct_par <- ParamFct$new("some_fct", levels = c("Male", "Female"))
fct_par

ParamSet$new(list(dbl_par, fct_par))
#+end_src

#+RESULTS:
#+begin_example

           id    class lower upper levels default
1: some_param ParamDbl     0     1            0.5

         id    class lower upper      levels     default
1: some_fct ParamFct    NA    NA Male,Female <NoDefault>

ParamSet: 
           id    class lower upper      levels     default value
1: some_param ParamDbl     0     1                     0.5      
2:   some_fct ParamFct    NA    NA Male,Female <
#+end_example

*** 1. パラメタスペースを作成

- ={rpart}= のパラメタをチューニング
#+begin_src R
task <- tsk("pima")
learner <- lrn("classif.rpart")
learner$param_set
#+end_src

#+RESULTS:
: ParamSet: 
:              id    class lower upper levels default value
: 1:     minsplit ParamInt     1   Inf             20      
: 2:           cp ParamDbl     0     1           0.01      
: 3:   maxcompete ParamInt     0   Inf              4      
: 4: maxsurrogate ParamInt     0   Inf              5      
: 5:     maxdepth ParamInt     1    30             30      
: 6:         xval ParamInt     0   Inf             10     0

- パラメタスペースを定義
#+begin_src R
tune_ps <- ParamSet$new(list(
  ParamDbl$new("cp", lower = 0.001, upper = 0.1),
  ParamInt$new("minsplit", lower = 1, upper = 10)
))
tune_ps
#+end_src

#+RESULTS:
: ParamSet: 
:          id    class lower upper levels     default value
: 1:       cp ParamDbl 0.001   0.1        <
:      
: 2: minsplit ParamInt 1.000  10.0        <

*** 2. ターミネーターを選択

- いつチューニングの計算を止めるか
  - none         止めない
  - evals        指定の試行回数
  - clock_time   時間経過後
  - model_time   モデルにかかった経過時間
  - combo        複数条件の組み合わせ (any or all)
  - perf_reached 指定の評価指標に至ったら
  - stagnation   指定回数経過してもパフォーマンスが向上しなかったら

#+begin_src R
mlr_terminators

## none
term("none")

## evals
term("evals", n_evals = 5)

## clock_time
term("clock_time", secs = 1800)
stop_time = as.POSIXct("2030-01-01 00:00:00")
term("clock_time", stop_time = stop_time)

## model_time
term("model_time", secs = 10 * 3600)

## perf_reached
term("perf_reached", level = 0.5)

## statgnation
term("stagnation", iters = 5, threshold = 1e-5)

## combo
term("combo",
  list(term("model_time", secs = 60), term("evals", n_evals = 10)),
  any = FALSE
)
#+end_src

#+RESULTS:
#+begin_example
<
with 7 stored values
Keys: clock_time, combo, evals, model_time, none, perf_reached,
  stagnation

<TerminatorNone>
,* Parameters: list()

<TerminatorEvals>
,* Parameters: n_evals=5

<TerminatorClockTime>
,* Parameters: secs=1800

<TerminatorClockTime>
,* Parameters: stop_time=<POSIXct>

<TerminatorModelTime>
,* Parameters: secs=3.6e+04

<TerminatorPerfReached>
,* Parameters: level=0.5

<TerminatorStagnation>
,* Parameters: iters=5, threshold=1e-05

<TerminatorCombo>
,* Parameters: any=FALSE
#+end_example

*** 3. チューニングインスタンスを作成

#+begin_src R
hout <- rsmp("holdout")
measure <- msr("classif.ce")

instance <- TuningInstance$new(
  task = task,
  learner = learner,
  resampling = hout,
  measures = measure,
  param_set = tune_ps,
  terminator = evals20
)
instance
#+end_src

#+RESULTS:
#+begin_example
<TuningInstance>
,* Task: <TaskClassif:pima>
,* Learner: <LearnerClassifRpart:classif.rpart>
,* Measures: classif.ce
,* Resampling: <ResamplingHoldout>
,* Terminator: <TerminatorEvals>
,* bm_args: list()
ParamSet: 
         id    class lower upper levels     default value
1:       cp ParamDbl 0.001   0.1        <
     
2: minsplit ParamInt 1.000  10.0        <
     
Archive:
Empty data.table (0 rows and 11 cols): nr,batch_nr,resample_result,task_id,learner_id,resampling_id...
#+end_example

*** 4. 最適化アルゴリズムを選択

- アルゴリズム一覧
  - グリッドサーチ ="grid_search"=
  - ランダムサーチ ="random_search"=
  - 焼きなまし法 (疑似アーニング法) ="gensa"=
  - ="design_points"=

- ={mlr3tuning}= にはベイズ最適化は実装されていない

#+begin_src R
mlr_tuners

tuner <- tnr("grid_search", resolution = 5)
tuner
#+end_src

#+RESULTS:
: <
: with 4 stored values
: Keys: design_points, gensa, grid_search, random_search
: <TunerGridSearch>
: * Parameters: resolution=5, batch_size=1
: * Packages: -
: * Properties: dependencies

*** 5. チューニング実行

- Tuner に TuningInstance を渡す
#+begin_src R
tuner$tune(instance)
instance$archive()
#+end_src

#+RESULTS:
#+begin_example
INFO  [11:00:57.995] Starting to tune 2 parameters with '<TunerGridSearch>' and '<TerminatorEvals>' 
INFO  [11:00:57.997] Terminator settings: n_evals=20 
INFO  [11:00:58.001] Finished tuning after 20 evals
    nr batch_nr  resample_result task_id    learner_id resampling_id iters
 1:  1        1 <
   pima classif.rpart       holdout     1
 2:  2        2 <
   pima classif.rpart       holdout     1
 3:  3        3 <
   pima classif.rpart       holdout     1
 4:  4        4 <
   pima classif.rpart       holdout     1
 5:  5        5 <
   pima classif.rpart       holdout     1
 6:  6        6 <
   pima classif.rpart       holdout     1
 7:  7        7 <
   pima classif.rpart       holdout     1
 8:  8        8 <
   pima classif.rpart       holdout     1
 9:  9        9 <
   pima classif.rpart       holdout     1
10: 10       10 <
   pima classif.rpart       holdout     1
11: 11       11 <
   pima classif.rpart       holdout     1
12: 12       12 <
   pima classif.rpart       holdout     1
13: 13       13 <
   pima classif.rpart       holdout     1
14: 14       14 <
   pima classif.rpart       holdout     1
15: 15       15 <
   pima classif.rpart       holdout     1
16: 16       16 <
   pima classif.rpart       holdout     1
17: 17       17 <
   pima classif.rpart       holdout     1
18: 18       18 <
   pima classif.rpart       holdout     1
19: 19       19 <
   pima classif.rpart       holdout     1
20: 20       20 <
   pima classif.rpart       holdout     1
    params tune_x warnings errors classif.ce
 1: <
<
       0      0  0.2968750
 2: <
<
       0      0  0.2578125
 3: <
<
       0      0  0.2578125
 4: <
<
       0      0  0.2578125
 5: <
<
       0      0  0.3164062
 6: <
<
       0      0  0.2578125
 7: <
<
       0      0  0.2578125
 8: <
<
       0      0  0.2929688
 9: <
<
       0      0  0.2578125
10: <
<
       0      0  0.2578125
11: <
<
       0      0  0.2578125
12: <
<
       0      0  0.2578125
13: <
<
       0      0  0.2578125
14: <
<
       0      0  0.2578125
15: <
<
       0      0  0.3046875
16: <
<
       0      0  0.2578125
17: <
<
       0      0  0.2578125
18: <
<
       0      0  0.2578125
19: <
<
       0      0  0.2578125
20: <
<
       0      0  0.2578125
#+end_example

#+begin_src R
instance$archive(unnest = "params")[, c("cp", "minsplit", "classif.ce")]
#+end_src

#+RESULTS:
#+begin_example
         cp minsplit classif.ce
 1: 0.00100        1  0.2968750
 2: 0.07525        1  0.2578125
 3: 0.07525       10  0.2578125
 4: 0.10000        5  0.2578125
 5: 0.00100        5  0.3164062
 6: 0.07525        8  0.2578125
 7: 0.05050        5  0.2578125
 8: 0.00100        3  0.2929688
 9: 0.10000       10  0.2578125
10: 0.05050        8  0.2578125
11: 0.02575        1  0.2578125
12: 0.02575        8  0.2578125
13: 0.02575        3  0.2578125
14: 0.07525        3  0.2578125
15: 0.00100       10  0.3046875
16: 0.05050        1  0.2578125
17: 0.07525        5  0.2578125
18: 0.02575       10  0.2578125
19: 0.10000        3  0.2578125
20: 0.02575        5  0.2578125
#+end_example

*** 6. 自動チューニング

- =AutoTuner= class (=Learner= class でもある)
- AutoTuner は通常の Learner として =train()= -> =predict()= を使うことができる
- ここでは、デフォルトのパラメタとの比較のため、grid を作成
- チューニングの resampling と最終的な評価の resampling を分けている (nested resampling)
  - =benchmark()= もしくは =resample()= を使う
#+begin_src R
learner <- lrn("classif.rpart")
resampling <- rsmp("holdout")
measures <- msr("classif.ce")
tune_ps <- ParamSet$new(list(
  ParamDbl$new("cp", lower = 0.001, upper = 0.1),
  ParamInt$new("minsplit", lower = 1, upper = 10)
))
terminator = term("evals", n_evals = 10)
tuner = tnr("random_search")

at <- AutoTuner$new(
  learner = learner,
  resampling = resampling,
  measures = measures,
  tune_ps = tune_ps,
  terminator = terminator,
  tuner = tuner)
at

grid <- benchmark_grid(
  task = tsk("pima"),
  learner = list(at, lrn("classif.rpart")),
  resampling = rsmp("cv", folds = 3)
)

bmr <- benchmark(grid)
bmr$aggregate(measures)
#+end_src

#+RESULTS:
#+begin_example
<AutoTuner:classif.rpart.tuned>
,* Model: -
,* Parameters: xval=0
,* Packages: rpart
,* Predict Type: response
,* Feature types: logical, integer, numeric, factor, ordered
,* Properties: importance, missings, multiclass, selected_features,
  twoclass, weights
INFO  [11:14:58.373] Benchmark with 6 resampling iterations 
INFO  [11:14:58.375] Applying learner 'classif.rpart.tuned' on task 'pima' (iter 1/3) 
INFO  [11:14:58.394] Starting to tune 2 parameters with '<TunerRandomSearch>' and '<TerminatorEvals>' 
INFO  [11:14:58.396] Terminator settings: n_evals=10 
INFO  [11:14:58.412] Evaluating 1 configurations 
INFO  [11:14:58.421]          cp minsplit 
INFO  [11:14:58.421]  0.02033822        1 
INFO  [11:14:58.441] Benchmark with 1 resampling iterations 
INFO  [11:14:58.443] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.461] Finished benchmark 
INFO  [11:14:58.471] Result: 
INFO  [11:14:58.474]          cp minsplit classif.ce 
INFO  [11:14:58.474]  0.02033822        1  0.2748538 
INFO  [11:14:58.493] Evaluating 1 configurations 
INFO  [11:14:58.496]          cp minsplit 
INFO  [11:14:58.496]  0.05419673        3 
INFO  [11:14:58.511] Benchmark with 1 resampling iterations 
INFO  [11:14:58.513] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.536] Finished benchmark 
INFO  [11:14:58.547] Result: 
INFO  [11:14:58.551]          cp minsplit classif.ce 
INFO  [11:14:58.551]  0.05419673        3  0.3216374 
INFO  [11:14:58.576] Evaluating 1 configurations 
INFO  [11:14:58.579]          cp minsplit 
INFO  [11:14:58.579]  0.08287912       10 
INFO  [11:14:58.593] Benchmark with 1 resampling iterations 
INFO  [11:14:58.595] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.614] Finished benchmark 
INFO  [11:14:58.624] Result: 
INFO  [11:14:58.627]          cp minsplit classif.ce 
INFO  [11:14:58.627]  0.08287912       10  0.3216374 
INFO  [11:14:58.646] Evaluating 1 configurations 
INFO  [11:14:58.649]           cp minsplit 
INFO  [11:14:58.649]  0.004289158       10 
INFO  [11:14:58.664] Benchmark with 1 resampling iterations 
INFO  [11:14:58.665] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.684] Finished benchmark 
INFO  [11:14:58.694] Result: 
INFO  [11:14:58.697]           cp minsplit classif.ce 
INFO  [11:14:58.697]  0.004289158       10  0.3157895 
INFO  [11:14:58.724] Evaluating 1 configurations 
INFO  [11:14:58.727]          cp minsplit 
INFO  [11:14:58.727]  0.08916387        9 
INFO  [11:14:58.742] Benchmark with 1 resampling iterations 
INFO  [11:14:58.743] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.761] Finished benchmark 
INFO  [11:14:58.771] Result: 
INFO  [11:14:58.774]          cp minsplit classif.ce 
INFO  [11:14:58.774]  0.08916387        9  0.3216374 
INFO  [11:14:58.792] Evaluating 1 configurations 
INFO  [11:14:58.794]          cp minsplit 
INFO  [11:14:58.794]  0.07341031        3 
INFO  [11:14:58.808] Benchmark with 1 resampling iterations 
INFO  [11:14:58.810] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.828] Finished benchmark 
INFO  [11:14:58.837] Result: 
INFO  [11:14:58.840]          cp minsplit classif.ce 
INFO  [11:14:58.840]  0.07341031        3  0.3216374 
INFO  [11:14:58.858] Evaluating 1 configurations 
INFO  [11:14:58.861]          cp minsplit 
INFO  [11:14:58.861]  0.01873271        2 
INFO  [11:14:58.875] Benchmark with 1 resampling iterations 
INFO  [11:14:58.877] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.895] Finished benchmark 
INFO  [11:14:58.904] Result: 
INFO  [11:14:58.907]          cp minsplit classif.ce 
INFO  [11:14:58.907]  0.01873271        2  0.2748538 
INFO  [11:14:58.925] Evaluating 1 configurations 
INFO  [11:14:58.927]          cp minsplit 
INFO  [11:14:58.927]  0.08816321       10 
INFO  [11:14:58.938] Benchmark with 1 resampling iterations 
INFO  [11:14:58.940] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:58.955] Finished benchmark 
INFO  [11:14:58.970] Result: 
INFO  [11:14:58.974]          cp minsplit classif.ce 
INFO  [11:14:58.974]  0.08816321       10  0.3216374 
INFO  [11:14:58.990] Evaluating 1 configurations 
INFO  [11:14:58.992]          cp minsplit 
INFO  [11:14:58.992]  0.01842421        5 
INFO  [11:14:59.003] Benchmark with 1 resampling iterations 
INFO  [11:14:59.004] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.020] Finished benchmark 
INFO  [11:14:59.028] Result: 
INFO  [11:14:59.031]          cp minsplit classif.ce 
INFO  [11:14:59.031]  0.01842421        5  0.2748538 
INFO  [11:14:59.046] Evaluating 1 configurations 
INFO  [11:14:59.049]          cp minsplit 
INFO  [11:14:59.049]  0.03568032        7 
INFO  [11:14:59.061] Benchmark with 1 resampling iterations 
INFO  [11:14:59.064] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.081] Finished benchmark 
INFO  [11:14:59.089] Result: 
INFO  [11:14:59.092]          cp minsplit classif.ce 
INFO  [11:14:59.092]  0.03568032        7  0.2690058 
INFO  [11:14:59.095] Finished tuning after 10 evals 
INFO  [11:14:59.131] Applying learner 'classif.rpart.tuned' on task 'pima' (iter 2/3) 
INFO  [11:14:59.147] Starting to tune 2 parameters with '<TunerRandomSearch>' and '<TerminatorEvals>' 
INFO  [11:14:59.149] Terminator settings: n_evals=10 
INFO  [11:14:59.163] Evaluating 1 configurations 
INFO  [11:14:59.165]          cp minsplit 
INFO  [11:14:59.165]  0.02857727        4 
INFO  [11:14:59.182] Benchmark with 1 resampling iterations 
INFO  [11:14:59.184] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.207] Finished benchmark 
INFO  [11:14:59.218] Result: 
INFO  [11:14:59.221]          cp minsplit classif.ce 
INFO  [11:14:59.221]  0.02857727        4  0.2573099 
INFO  [11:14:59.239] Evaluating 1 configurations 
INFO  [11:14:59.241]          cp minsplit 
INFO  [11:14:59.241]  0.05260777        5 
INFO  [11:14:59.253] Benchmark with 1 resampling iterations 
INFO  [11:14:59.254] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.269] Finished benchmark 
INFO  [11:14:59.277] Result: 
INFO  [11:14:59.279]          cp minsplit classif.ce 
INFO  [11:14:59.279]  0.05260777        5  0.2573099 
INFO  [11:14:59.295] Evaluating 1 configurations 
INFO  [11:14:59.298]          cp minsplit 
INFO  [11:14:59.298]  0.07034902        6 
INFO  [11:14:59.309] Benchmark with 1 resampling iterations 
INFO  [11:14:59.311] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.328] Finished benchmark 
INFO  [11:14:59.338] Result: 
INFO  [11:14:59.341]          cp minsplit classif.ce 
INFO  [11:14:59.341]  0.07034902        6  0.2573099 
INFO  [11:14:59.357] Evaluating 1 configurations 
INFO  [11:14:59.359]          cp minsplit 
INFO  [11:14:59.359]  0.04001921        9 
INFO  [11:14:59.371] Benchmark with 1 resampling iterations 
INFO  [11:14:59.372] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.388] Finished benchmark 
INFO  [11:14:59.396] Result: 
INFO  [11:14:59.399]          cp minsplit classif.ce 
INFO  [11:14:59.399]  0.04001921        9  0.2573099 
INFO  [11:14:59.415] Evaluating 1 configurations 
INFO  [11:14:59.417]           cp minsplit 
INFO  [11:14:59.417]  0.009687906        8 
INFO  [11:14:59.435] Benchmark with 1 resampling iterations 
INFO  [11:14:59.437] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.454] Finished benchmark 
INFO  [11:14:59.461] Result: 
INFO  [11:14:59.464]           cp minsplit classif.ce 
INFO  [11:14:59.464]  0.009687906        8   0.245614 
INFO  [11:14:59.479] Evaluating 1 configurations 
INFO  [11:14:59.482]          cp minsplit 
INFO  [11:14:59.482]  0.05188145        7 
INFO  [11:14:59.496] Benchmark with 1 resampling iterations 
INFO  [11:14:59.497] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.515] Finished benchmark 
INFO  [11:14:59.527] Result: 
INFO  [11:14:59.531]          cp minsplit classif.ce 
INFO  [11:14:59.531]  0.05188145        7  0.2573099 
INFO  [11:14:59.556] Evaluating 1 configurations 
INFO  [11:14:59.559]         cp minsplit 
INFO  [11:14:59.559]  0.0149599        1 
INFO  [11:14:59.575] Benchmark with 1 resampling iterations 
INFO  [11:14:59.577] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.594] Finished benchmark 
INFO  [11:14:59.601] Result: 
INFO  [11:14:59.604]         cp minsplit classif.ce 
INFO  [11:14:59.604]  0.0149599        1  0.2573099 
INFO  [11:14:59.621] Evaluating 1 configurations 
INFO  [11:14:59.623]          cp minsplit 
INFO  [11:14:59.623]  0.05937711        2 
INFO  [11:14:59.635] Benchmark with 1 resampling iterations 
INFO  [11:14:59.636] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.651] Finished benchmark 
INFO  [11:14:59.659] Result: 
INFO  [11:14:59.662]          cp minsplit classif.ce 
INFO  [11:14:59.662]  0.05937711        2  0.2573099 
INFO  [11:14:59.685] Evaluating 1 configurations 
INFO  [11:14:59.688]          cp minsplit 
INFO  [11:14:59.688]  0.02140892       10 
INFO  [11:14:59.700] Benchmark with 1 resampling iterations 
INFO  [11:14:59.702] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.719] Finished benchmark 
INFO  [11:14:59.727] Result: 
INFO  [11:14:59.729]          cp minsplit classif.ce 
INFO  [11:14:59.729]  0.02140892       10  0.2573099 
INFO  [11:14:59.745] Evaluating 1 configurations 
INFO  [11:14:59.748]          cp minsplit 
INFO  [11:14:59.748]  0.04334273        6 
INFO  [11:14:59.758] Benchmark with 1 resampling iterations 
INFO  [11:14:59.760] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.775] Finished benchmark 
INFO  [11:14:59.782] Result: 
INFO  [11:14:59.785]          cp minsplit classif.ce 
INFO  [11:14:59.785]  0.04334273        6  0.2573099 
INFO  [11:14:59.787] Finished tuning after 10 evals 
INFO  [11:14:59.822] Applying learner 'classif.rpart.tuned' on task 'pima' (iter 3/3) 
INFO  [11:14:59.837] Starting to tune 2 parameters with '<TunerRandomSearch>' and '<TerminatorEvals>' 
INFO  [11:14:59.839] Terminator settings: n_evals=10 
INFO  [11:14:59.850] Evaluating 1 configurations 
INFO  [11:14:59.853]          cp minsplit 
INFO  [11:14:59.853]  0.09093063        8 
INFO  [11:14:59.868] Benchmark with 1 resampling iterations 
INFO  [11:14:59.869] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.884] Finished benchmark 
INFO  [11:14:59.892] Result: 
INFO  [11:14:59.895]          cp minsplit classif.ce 
INFO  [11:14:59.895]  0.09093063        8  0.2339181 
INFO  [11:14:59.919] Evaluating 1 configurations 
INFO  [11:14:59.922]          cp minsplit 
INFO  [11:14:59.922]  0.01948108        9 
INFO  [11:14:59.934] Benchmark with 1 resampling iterations 
INFO  [11:14:59.936] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:14:59.954] Finished benchmark 
INFO  [11:14:59.963] Result: 
INFO  [11:14:59.966]          cp minsplit classif.ce 
INFO  [11:14:59.966]  0.01948108        9  0.2748538 
INFO  [11:14:59.984] Evaluating 1 configurations 
INFO  [11:14:59.987]           cp minsplit 
INFO  [11:14:59.987]  0.002749909        5 
INFO  [11:15:00.001] Benchmark with 1 resampling iterations 
INFO  [11:15:00.003] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.022] Finished benchmark 
INFO  [11:15:00.032] Result: 
INFO  [11:15:00.035]           cp minsplit classif.ce 
INFO  [11:15:00.035]  0.002749909        5  0.3216374 
INFO  [11:15:00.052] Evaluating 1 configurations 
INFO  [11:15:00.054]          cp minsplit 
INFO  [11:15:00.054]  0.04210418        5 
INFO  [11:15:00.070] Benchmark with 1 resampling iterations 
INFO  [11:15:00.071] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.087] Finished benchmark 
INFO  [11:15:00.095] Result: 
INFO  [11:15:00.098]          cp minsplit classif.ce 
INFO  [11:15:00.098]  0.04210418        5  0.2339181 
INFO  [11:15:00.114] Evaluating 1 configurations 
INFO  [11:15:00.116]         cp minsplit 
INFO  [11:15:00.116]  0.0301537        9 
INFO  [11:15:00.128] Benchmark with 1 resampling iterations 
INFO  [11:15:00.129] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.152] Finished benchmark 
INFO  [11:15:00.162] Result: 
INFO  [11:15:00.166]         cp minsplit classif.ce 
INFO  [11:15:00.166]  0.0301537        9  0.2397661 
INFO  [11:15:00.183] Evaluating 1 configurations 
INFO  [11:15:00.186]          cp minsplit 
INFO  [11:15:00.186]  0.06608045       10 
INFO  [11:15:00.200] Benchmark with 1 resampling iterations 
INFO  [11:15:00.201] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.219] Finished benchmark 
INFO  [11:15:00.228] Result: 
INFO  [11:15:00.231]          cp minsplit classif.ce 
INFO  [11:15:00.231]  0.06608045       10  0.2339181 
INFO  [11:15:00.248] Evaluating 1 configurations 
INFO  [11:15:00.251]           cp minsplit 
INFO  [11:15:00.251]  0.002372216        9 
INFO  [11:15:00.264] Benchmark with 1 resampling iterations 
INFO  [11:15:00.266] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.284] Finished benchmark 
INFO  [11:15:00.294] Result: 
INFO  [11:15:00.297]           cp minsplit classif.ce 
INFO  [11:15:00.297]  0.002372216        9  0.2573099 
INFO  [11:15:00.315] Evaluating 1 configurations 
INFO  [11:15:00.318]         cp minsplit 
INFO  [11:15:00.318]  0.0197219        8 
INFO  [11:15:00.332] Benchmark with 1 resampling iterations 
INFO  [11:15:00.333] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.351] Finished benchmark 
INFO  [11:15:00.360] Result: 
INFO  [11:15:00.363]         cp minsplit classif.ce 
INFO  [11:15:00.363]  0.0197219        8  0.2748538 
INFO  [11:15:00.381] Evaluating 1 configurations 
INFO  [11:15:00.384]          cp minsplit 
INFO  [11:15:00.384]  0.08390787       10 
INFO  [11:15:00.406] Benchmark with 1 resampling iterations 
INFO  [11:15:00.408] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.426] Finished benchmark 
INFO  [11:15:00.435] Result: 
INFO  [11:15:00.438]          cp minsplit classif.ce 
INFO  [11:15:00.438]  0.08390787       10  0.2339181 
INFO  [11:15:00.456] Evaluating 1 configurations 
INFO  [11:15:00.458]          cp minsplit 
INFO  [11:15:00.458]  0.02929757        4 
INFO  [11:15:00.472] Benchmark with 1 resampling iterations 
INFO  [11:15:00.474] Applying learner 'classif.rpart' on task 'pima' (iter 1/1) 
INFO  [11:15:00.491] Finished benchmark 
INFO  [11:15:00.500] Result: 
INFO  [11:15:00.503]          cp minsplit classif.ce 
INFO  [11:15:00.503]  0.02929757        4  0.2397661 
INFO  [11:15:00.506] Finished tuning after 10 evals 
INFO  [11:15:00.559] Applying learner 'classif.rpart' on task 'pima' (iter 1/3) 
INFO  [11:15:00.578] Applying learner 'classif.rpart' on task 'pima' (iter 2/3) 
INFO  [11:15:00.594] Applying learner 'classif.rpart' on task 'pima' (iter 3/3) 
INFO  [11:15:00.617] Finished benchmark
   nr  resample_result task_id          learner_id resampling_id iters
1:  1 <
   pima classif.rpart.tuned            cv     3
2:  2 <
   pima       classif.rpart            cv     3
   classif.ce
1:  0.2630208
2:  0.2513021
#+end_example

** 可視化 by ={mlr3viz}=

- ={mlr3viz}= の機能
- 以下のクラス向けに =autoplot(obj, type)= を提供
  - Task
  - Filter
  - Prediction
  - ResampleResult
  - BenchmarkResult

* 参考

- ={mlr3}=
  - [[https://mlr3.mlr-org.com/][公式サイト]]
  - [[https://cran.r-project.org/web/packages/mlr3/index.html][CRAN]]
  - [[https://github.com/mlr-org/mlr3][Github repo]]
  - [[https://mlr3book.mlr-org.com/][mlr3book]]
  - [[https://mlr3.mlr-org.com/reference/][Reference]]
  - [[https://cran.r-project.org/web/packages/mlr3/mlr3.pdf][Reference manual (PDF)]]
  - [[http://www.user2019.fr/static/pres/t258076.pdf][mlr3@UseR 2019]]

- ={mlr3pipelines}=
  - [[https://mlr3pipelines.mlr-org.com/reference/index.html][Reference]]

- ={mlr3tuning}=
  - [[https://mlr3tuning.mlr-org.com/reference/][Reference]]

- ={mlr3filters}=
  - [[https://mlr3filters.mlr-org.com/reference/index.html][Reference]]

- ={mlr3viz}=
  - [[https://mlr3viz.mlr-org.com/reference/index.html][Reference]]

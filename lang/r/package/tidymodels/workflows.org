#+STARTUP: folded indent
#+PROPERTY: header-args:R :results output :colnames yes :session *R:workflows*

* ~{workflows}~: Modeling Workflows                                 :noexport:
* ライブラリの読み込みとバージョンの確認

#+begin_src R :results silent
library(workflows)
library(tidyverse)
library(tidymodels)
#+end_src

- バージョン
#+begin_src R :results output :exports both
packageVersion("workflows")
#+end_src

#+RESULTS:
: [1] ‘0.0.0.9002’

* 全関数リスト

#+begin_src R :results output
pacman::p_funs(workflows)
#+end_src

#+RESULTS:
:  [1] ".fit_model"                   ".fit_pre"                    
:  [3] "add_formula"                  "add_model"                   
:  [5] "add_recipe"                   "control_workflow"            
:  [7] "pull_workflow_fit"            "pull_workflow_mold"          
:  [9] "pull_workflow_prepped_recipe" "pull_workflow_preprocessor"  
: [11] "pull_workflow_spec"           "remove_formula"              
: [13] "remove_model"                 "remove_recipe"               
: [15] "update_formula"               "update_model"                
: [17] "update_recipe"                "workflow"

* 概要
** ワークフロー

以下の 3 つを統合して扱う
- 前処理
  - =add_formula()=, =remove_formula()=, =update_formula()=
  - =add_recipe()=, =remove_recipe()=, =update_recipe()=
- モデル
  - =add_model()=, =remove_model()=, =update_model()=
  - ={parsnip}= のモデルのみ現在は対応
- 後処理
  - 現在は未実装

- Utility
  - =pull_workflow_***(workflow)= でオブジェクトを抽出
  - =control_workflow()= で配下の ={parsnip}= モデルの挙動などを制御

- {tune}

** マニュアルの例

#+begin_src R
## レシピ
spline_cars <- recipe(mpg ~ ., data = mtcars) %>%
  step_ns(disp, deg_free = 10)

## モデル
bayes_lm <- linear_reg() %>%
  set_engine("stan")

## ワークフローとして統合
car_wflow <- workflow() %>%
  add_recipe(spline_cars) %>%
  add_model(bayes_lm)

## Fit
car_wflow_fit <- fit(car_wflow, data = mtcars)
car_wflow_fit
#+end_src

#+RESULTS:
#+begin_example

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 2.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.508945 seconds (Warm-up)
Chain 1:                0.434115 seconds (Sampling)
Chain 1:                0.94306 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1.6e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.499341 seconds (Warm-up)
Chain 2:                0.448293 seconds (Sampling)
Chain 2:                0.947634 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 2.1e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.478938 seconds (Warm-up)
Chain 3:                0.429656 seconds (Sampling)
Chain 3:                0.908594 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1.4e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.456778 seconds (Warm-up)
Chain 4:                0.425617 seconds (Sampling)
Chain 4:                0.882395 seconds (Total)
Chain 4:
══ Workflow [trained] ══════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: linear_reg()

── Preprocessor ────────────────────────────────────────────────────────────────
1 Recipe Step

● step_ns()

── Model ───────────────────────────────────────────────────────────────────────
stan_glm
 family:       gaussian [identity]
 formula:      ..y ~ .
 observations: 32
 predictors:   20
------
            Median MAD_SD
(Intercept)  49.0   17.5 
cyl          -3.2    1.4 
hp            0.0    0.0 
drat         -2.7    1.6 
wt           -1.0    1.5 
qsec          0.2    0.7 
vs           -2.7    2.0 
am           -1.0    1.7 
gear          2.8    1.2 
carb          0.3    1.2 
disp_ns_01   -9.8    3.8 
disp_ns_02  -12.6    4.0 
disp_ns_03   -4.9    4.0 
disp_ns_04  -15.3    5.8 
disp_ns_05    0.0    5.1 
disp_ns_06   -6.6    5.3 
disp_ns_07   -3.5    6.3 
disp_ns_08    5.5    5.9 
disp_ns_09   -9.8    7.9 
disp_ns_10   -4.4    5.8 

Auxiliary parameter(s):
      Median MAD_SD
sigma 1.6    0.3   

------
,* For help interpreting the printed output see ?print.stanreg
,* For info on the priors used see ?prior_summary.stanreg
#+end_example

* 関数リスト
** 対応モデル
*** mode = "unknown" (分類・回帰どちらも使えるモデル)
**** ~svm_poly(mode = "unknown", cost = NULL, degree = NULL, scale_factor = NULL, margin = NULL)~.

- Support Vector Machine
- 非線形多項式 カーネルを利用するモデル
- Engines
  - "kernlab": =kernlab::ksvm()= (the default)

*ハイパーパラメタ*
- =cost=:
  - The cost of predicting a sample within or on the wrong side of the margin.
  - ソフトマージン (誤判定の許容度)
- =degree=:
  - The polynomial degree.
- =scale_factor=: 
  - A scaling factor for the kernel.
- =margin=: 
  - The epsilon in the SVM insensitive loss function (regression only)

**** ~svm_rbf(mode = "unknown", cost = NULL, rbf_sigma = NULL, margin = NULL)~.

- SVM Radial Basis Function
- RBF カーネルを利用するモデル
- Engines
  - "kernlab": =kernlab::ksvm()= (the default)

*ハイパーパラメタ*
- =cost=:
  - The cost of predicting a sample within or on the wrong side of the margin.
  - ソフトマージン (誤判定の許容度)
- =rbf_sigma=:
  - The precision parameter for the radial basis function.
- =margin=:
  - The epsilon in the SVM insensitive loss function (regression only)

**** ~decision_tree(mode = "unknown", cost_complexity = NULL, tree_depth = NULL, min_n = NULL)~.

- 決定木
- Engines
  - "rpart": =rpart::rpart()= (default)
  - "C5.0":  =parsnip::C5.0_train()= (classification only)
  - "spark": =sparklyr::ml_decision_tree_classifier()=

*ハイパーパラメタ*
- =cost_complexity=: 
  - The cost/complexity parameter (a.k.a. Cp) used by CART models
  - ={rpart}= only
- =tree_depth=:
  - The maximum depth of a tree 
  - ={rpart}= and ={spark}=
- =min_n=:
  - The minimum number of data points in a node that are required for the node to be split further.

**** ~rand_forest(mode = "unknown", mtry = NULL, trees = NULL, min_n = NULL)~.

- ランダムフォレスト
- Engines
  - "ranger":       =ranger::ranger()= (default)
  - "randomForest": =randomForest::randomForest()=
  - "spark":        =sparklyr::ml_random_forest()=

- 引数 (ハイパーパラメター)
  - mtry
  - trees
  - min_n

**** ~boost_tree(mode = "unknown", mtry = NULL, trees = NULL, min_n = NULL, tree_depth = NULL, learn_rate = NULL, loss_reduction = NULL, sample_size = NULL)~.

- 勾配ブースティング (Gradient Boosting)
- Engines
  - "xgboost": =parsnip::xgb_train()= (default)
  - "C5.0":    =parsnip::C5.0_train()=
  - "spark":   =sparklyr::ml_gradient_boosted_trees()=

**** ~mars(mode = "unknown", num_terms = NULL, prod_degree = NULL, prune_method = NULL)~.

- MARS (Multivariate Adaptive Regression Splines = 多変量適応型回帰スプライン法)
- Engines
  - "earth": =earth::earth()=

**** ~mlp(mode = "unknown", hidden_units = NULL, penalty = NULL, dropout = NULL, epochs = NULL, activation = NULL)~.

- Multilayer Perceptron 多層パーセプトロン
- Engines
  - "nnet":  =nnet::nnet()= (default)
  - "keras": =parsnip::keras_mlp()=

*ハイパーパラメタ*
- =hidden_units=: The number of units in the hidden layer (default: 5).
- =penalty=: The amount of L2 regularization (aka weight decay, default is zero).
- =dropout=: The proportion of parameters randomly dropped out of the model (keras only, default is zero).
- =epochs=: The number of training iterations (default: 20).
- =activation=: 活性化関数 (keras のみ。デフォルト softmax)

**** ~nearest_neighbor(mode = "unknown", neighbors = NULL, weight_func = NULL, dist_power = NULL)~.

- k 近傍法 (k-nearest neighbor algorithm, k-NN)
- Engines
  - "kknn": =kknn::train.kknn()= (default)

*ハイパーパラメタ*
- =neighbors=
  - The number of neighbors considered at each prediction.
- =weight_func=
   - The type of kernel function that weights the distances between samples.
- =dist_power=
  - The parameter used when calculating the Minkowski distance.
  - Manhattan distance with =dist_power = 1=
  - Euclidean distance with =dist_power = 2=

*** mode = "classification"
**** ~logistic_reg(mode = "classification", penalty = NULL, mixture = NULL)~.

- Engines
  - glm:    =stats::glm()= (default)
  - glmnet: =glmnet::glmnet()=
  - stan:   =rstanarm::stan_glm()=
  - spark:  =sparklyr::ml_logistic_regression()=
  - keras:  =parsnip::keras_mlp()=

*ハイパーパラメタ*
- =penalty=
  - 正則化の程度を決める非負の数値 (={glmnet}=, ={keras}=, ={spark}= で有効)
  - lambda に相当
  - stats::glm() などでは、0 にする
- =mixture=
  - 0-1 の数値 (={glmnet}=, ={spark}= で有効)
  - ElasticNet の alpha に相当? (Lasso = L1 の比率で指定)
  - 1 = Lasso, 0 = Ridge, 0 ~ 1 = ElasticNet

その他
- 特徴量は、標準化されている必要がある

**** ~multinom_reg(mode = "classification", penalty = NULL, mixture = NULL)~.

- 多項ロジスティック回帰
- Engines
  - glmnet: =glmnet::glmnet()= (default)
  - spark:  =sparklyr::ml_logistic_regression()=
  - keras:  =parsnip::keras_mlp()=

**** ~null_model(mode = "classification")~.
*** mode = "regression"
**** ~linear_reg(mode = "regression", penalty = NULL, mixture = NULL)~.

- 対応エンジン
  • "lm":    =stats::lm()= (default)
  - "glmnet" =glmnet::glmnet()=
  • "stan"   =rstanarm::stan_glm()=
  • "spark"  =sparklyr::ml_linear_regression()=
  • "keras"  =parsnip::keras_mlp()=


正則化ありの回帰
- Lasso = L1 正則化を行う回帰 (係数の絶対値に応じて罰則)
- Ridge = L2 正則化を行う回帰 (係数の二乗に応じて罰則)
- ElasticNet = L1 + L2 正則化
- 正則化の度合いを決めるパラメタ lambda (Complexity Paramter) がハイパーパラメタ

**** ~surv_reg(mode = "regression", dist = NULL)~.

- Parametric Survival Models
- Engines
  - "survival": =survival::survreg()= (default)
  - "flexsurv": =flexsurv::flexsurvreg()=

** ユーティリティ関数
*** set_engine(object, engine, ...)
*** set_args(object, ...)
*** set_mode(object, mode)
* 実行環境

#+begin_src R :results output :exports both
sessionInfo()
#+end_src

#+RESULTS:
#+begin_example
R version 3.6.2 (2019-12-12)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] yardstick_0.0.4    rsample_0.0.5      recipes_0.1.7.9002 parsnip_0.0.4.9000
 [5] infer_0.5.0        dials_0.0.4.9000   scales_1.1.0       broom_0.5.2       
 [9] tidymodels_0.0.3   forcats_0.4.0      stringr_1.4.0      dplyr_0.8.3       
[13] purrr_0.3.3        readr_1.3.1        tidyr_1.0.0        tibble_2.1.3      
[17] ggplot2_3.2.1      tidyverse_1.2.1   

loaded via a namespace (and not attached):
  [1] readxl_1.3.1         backports_1.1.5      workflows_0.0.0.9002
  [4] tidytext_0.2.2       plyr_1.8.5           igraph_1.2.4.1      
  [7] lazyeval_0.2.2       splines_3.6.2        crosstalk_1.0.0     
 [10] listenv_0.8.0        SnowballC_0.6.0      rstantools_2.0.0    
 [13] inline_0.3.15        digest_0.6.23        htmltools_0.4.0     
 [16] rsconnect_0.8.15     fansi_0.4.0          magrittr_1.5        
 [19] globals_0.12.5       modelr_0.1.5         gower_0.2.1         
 [22] matrixStats_0.55.0   xts_0.11-2           prettyunits_1.0.2   
 [25] colorspace_1.4-2     rvest_0.3.4          haven_2.1.1         
 [28] xfun_0.10            callr_3.3.2          crayon_1.3.4        
 [31] jsonlite_1.6         lme4_1.1-21          zeallot_0.1.0       
 [34] survival_3.1-8       zoo_1.8-6            glue_1.3.1          
 [37] gtable_0.3.0         ipred_0.9-9          pkgbuild_1.0.6      
 [40] rstan_2.19.2         miniUI_0.1.1.1       Rcpp_1.0.3          
 [43] xtable_1.8-3         stats4_3.6.2         lava_1.6.6          
 [46] StanHeaders_2.19.0   prodlim_2019.11.13   DT_0.9              
 [49] htmlwidgets_1.5.1    httr_1.4.1           threejs_0.3.1       
 [52] pkgconfig_2.0.3      loo_2.1.0            nnet_7.3-12         
 [55] tidyselect_0.2.5     rlang_0.4.2.9000     DiceDesign_1.8-1    
 [58] reshape2_1.4.3       later_1.0.0          munsell_0.5.0       
 [61] cellranger_1.1.0     tools_3.6.2          cli_2.0.0.9000      
 [64] pacman_0.5.1         generics_0.0.2       ggridges_0.5.1      
 [67] fastmap_1.0.1        processx_3.4.1       knitr_1.25          
 [70] future_1.15.1        nlme_3.1-143         mime_0.7            
 [73] rstanarm_2.19.2      xml2_1.2.2           tokenizers_0.2.1    
 [76] compiler_3.6.2       bayesplot_1.7.0      shinythemes_1.1.2   
 [79] rstudioapi_0.10      tidyposterior_0.0.2  stringi_1.4.3       
 [82] ps_1.3.0             lattice_0.20-38      Matrix_1.2-18       
 [85] nloptr_1.2.1         markdown_1.1         shinyjs_1.0         
 [88] vctrs_0.2.1          pillar_1.4.3         lifecycle_0.1.0     
 [91] furrr_0.1.0          httpuv_1.5.2         R6_2.4.1            
 [94] promises_1.1.0       gridExtra_2.3        janeaustenr_0.1.5   
 [97] codetools_0.2-16     boot_1.3-24          colourpicker_1.0    
[100] MASS_7.3-51.5        gtools_3.8.1         assertthat_0.2.1    
[103] withr_2.1.2          shinystan_2.5.0      parallel_3.6.2      
[106] hms_0.5.1            grid_3.6.2           rpart_4.1-15        
[109] timeDate_3043.102    class_7.3-15         minqa_1.2.4         
[112] pROC_1.15.3          tidypredict_0.4.3    shiny_1.4.0         
[115] lubridate_1.7.4      base64enc_0.1-3      dygraphs_1.1.1.6
#+end_example
\\

* 参考リンク

- [[https://tidymodels.github.io/workflows/][公式サイト]]
- [[https://cloud.r-project.org/web/packages/workflows/index.html][CRAN]]
- [[https://cloud.r-project.org/web/packages/workflows/workflows.pdf][Reference Manual]]
- [[https://github.com/tidymodels/workflows][Github Repo]]

- Vignette
  - [[https://cloud.r-project.org/web/packages/workflows/vignettes/stages.html][Workflow Stages]]

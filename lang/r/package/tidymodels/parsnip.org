#+STARTUP: folded indent
#+PROPERTY: header-args:R :results output :colnames yes :session *R:parsnip*

* ={parsnip}=: A tidy unified interface to models                    :noexport:

={parsnip}= は複数のモデリングパッケージをラップするパッケージ。

{parsnip} 以外にも類似のアルゴリズムを提供するパッケージ
- {baguette}
- {discrim}
- {poissonreg}
- {plsmod}

* 目次                                                                :quote:
* ライブラリの読み込みとバージョンの確認

#+begin_src R :results silent
library(parsnip)
library(tidyverse)
library(tidymodels)
#+end_src

- バージョン
#+begin_src R :results output :exports both
packageVersion("parsnip")
#+end_src

#+RESULTS:
: [1] ‘0.1.1’

* 全関数リスト

#+begin_src R :results output
pacman::p_funs(parsnip)
#+end_src

#+RESULTS:
#+begin_example
 [1] "%>%"                         ".cols"                      
 [3] ".dat"                        ".facts"                     
 [5] ".lvls"                       ".obs"                       
 [7] ".preds"                      ".x"                         
 [9] ".y"                          "C5.0_train"                 
[11] "add_rowindex"                "boost_tree"                 
[13] "check_empty_ellipse"         "check_final_param"          
[15] "control_parsnip"             "convert_args"               
[17] "convert_stan_interval"       "decision_tree"              
[19] "eval_args"                   "fit"                        
[21] "fit.model_spec"              "fit_control"                
[23] "fit_xy"                      "fit_xy.model_spec"          
[25] "get_dependency"              "get_fit"                    
[27] "get_from_env"                "get_model_env"              
[29] "get_pred_type"               "has_multi_predict"          
[31] "is_varying"                  "keras_mlp"                  
[33] "linear_reg"                  "logistic_reg"               
[35] "make_classes"                "mars"                       
[37] "mlp"                         "model_printer"              
[39] "multi_predict"               "multi_predict_args"         
[41] "multinom_reg"                "nearest_neighbor"           
[43] "new_model_spec"              "null_model"                 
[45] "null_value"                  "nullmodel"                  
[47] "pred_value_template"         "predict.model_fit"          
[49] "predict_class.model_fit"     "predict_classprob.model_fit"
[51] "predict_confint.model_fit"   "predict_numeric"            
[53] "predict_numeric.model_fit"   "predict_quantile.model_fit" 
[55] "predict_raw"                 "predict_raw.model_fit"      
[57] "rand_forest"                 "rpart_train"                
[59] "set_args"                    "set_dependency"             
[61] "set_engine"                  "set_env_val"                
[63] "set_fit"                     "set_in_env"                 
[65] "set_mode"                    "set_model_arg"              
[67] "set_model_engine"            "set_model_mode"             
[69] "set_new_model"               "set_pred"                   
[71] "show_call"                   "show_fit"                   
[73] "show_model_info"             "surv_reg"                   
[75] "svm_poly"                    "svm_rbf"                    
[77] "tidy"                        "translate"                  
[79] "translate.default"           "update_dot_check"           
[81] "update_main_parameters"      "varying"                    
[83] "varying_args"                "xgb_train"
#+end_example

* 概要

- ~type~: モデルの種類
- ~mode~: 分類 (classification) or 回帰 (regression)
- ~engine~: 実際に処理をおこなうパッケージ

*ワークフロー*
1. モデルを選択
2. ~set_engine()~ でパッケージを選択
3. ~fit()~ でモデル当てはめ

Fitted object
- =model_fit= クラス
- 元のクラスにアンダーバー. 例) =_xgb.Booster= クラス
- 以下の要素を持つ
  - =$spec= parsnip のスペッククラス. 例) =boost_tree=, =mode_spec=
  - =$fit= エンジンから出力される fit object 例) =xgb.Booster=
  - =$elapsed=
  - =$lvl=
  - =$preproc=

* 関数リスト
** 対応モデル
*** mode = "unknown" (分類・回帰どちらも使えるモデル)
**** ~svm_poly(mode = "unknown", cost = NULL, degree = NULL, scale_factor = NULL, margin = NULL)~.

- Support Vector Machine
- 非線形多項式 カーネルを利用するモデル
- Engines
  - "kernlab": =kernlab::ksvm()= (the default)

*ハイパーパラメタ*
- =cost=:
  - The cost of predicting a sample within or on the wrong side of the margin.
  - ソフトマージン (誤判定の許容度)
- =degree=:
  - The polynomial degree.
- =scale_factor=: 
  - A scaling factor for the kernel.
- =margin=: 
  - The epsilon in the SVM insensitive loss function (regression only)

**** ~svm_rbf(mode = "unknown", cost = NULL, rbf_sigma = NULL, margin = NULL)~.

- SVM Radial Basis Function
- RBF カーネルを利用するモデル
- Engines
  - "kernlab": =kernlab::ksvm()= (the default)

*ハイパーパラメタ*
- =cost=:
  - The cost of predicting a sample within or on the wrong side of the margin.
  - ソフトマージン (誤判定の許容度)
- =rbf_sigma=:
  - The precision parameter for the radial basis function.
- =margin=:
  - The epsilon in the SVM insensitive loss function (regression only)

**** ~decision_tree(mode = "unknown", cost_complexity = NULL, tree_depth = NULL, min_n = NULL)~.

- 決定木
- Engines
  - "rpart": =rpart::rpart()= (default)
  - "C5.0":  =parsnip::C5.0_train()= (classification only)
  - "spark": =sparklyr::ml_decision_tree_classifier()=

*ハイパーパラメタ*
- =cost_complexity=: 
  - The cost/complexity parameter (a.k.a. Cp) used by CART models
  - ={rpart}= only
- =tree_depth=:
  - The maximum depth of a tree 
  - ={rpart}= and ={spark}=
- =min_n=:
  - The minimum number of data points in a node that are required for the node to be split further.

**** ~rand_forest(mode = "unknown", mtry = NULL, trees = NULL, min_n = NULL)~.

- ランダムフォレスト
- Engines
  - "ranger":       =ranger::ranger()= (default)
  - "randomForest": =randomForest::randomForest()=
  - "spark":        =sparklyr::ml_random_forest()=

- 引数 (ハイパーパラメター)
  - mtry
  - trees
  - min_n

**** ~boost_tree(mode = "unknown", mtry = NULL, trees = NULL, min_n = NULL, tree_depth = NULL, learn_rate = NULL, loss_reduction = NULL, sample_size = NULL)~.

- 勾配ブースティング (Gradient Boosting)
- Engines
  - "xgboost": =parsnip::xgb_train()= (default)
  - "C5.0":    =parsnip::C5.0_train()=
  - "spark":   =sparklyr::ml_gradient_boosted_trees()=

**** ~mars(mode = "unknown", num_terms = NULL, prod_degree = NULL, prune_method = NULL)~.

- MARS (Multivariate Adaptive Regression Splines = 多変量適応型回帰スプライン法)
- Engines
  - "earth": =earth::earth()=

**** ~mlp(mode = "unknown", hidden_units = NULL, penalty = NULL, dropout = NULL, epochs = NULL, activation = NULL)~.

- Multilayer Perceptron 多層パーセプトロン
- Engines
  - "nnet":  =nnet::nnet()= (default)
  - "keras": =parsnip::keras_mlp()=

*ハイパーパラメタ*
- =hidden_units=: The number of units in the hidden layer (default: 5).
- =penalty=: The amount of L2 regularization (aka weight decay, default is zero).
- =dropout=: The proportion of parameters randomly dropped out of the model (keras only, default is zero).
- =epochs=: The number of training iterations (default: 20).
- =activation=: 活性化関数 (keras のみ。デフォルト softmax)

**** ~nearest_neighbor(mode = "unknown", neighbors = NULL, weight_func = NULL, dist_power = NULL)~.

- k 近傍法 (k-nearest neighbor algorithm, k-NN)
- Engines
  - "kknn": =kknn::train.kknn()= (default)

*ハイパーパラメタ*
- =neighbors=
  - The number of neighbors considered at each prediction.
- =weight_func=
   - The type of kernel function that weights the distances between samples.
- =dist_power=
  - The parameter used when calculating the Minkowski distance.
  - Manhattan distance with =dist_power = 1=
  - Euclidean distance with =dist_power = 2=

*** mode = "classification"
**** ~logistic_reg(mode = "classification", penalty = NULL, mixture = NULL)~.

- Engines
  - glm:    =stats::glm()= (default)
  - glmnet: =glmnet::glmnet()=
  - stan:   =rstanarm::stan_glm()=
  - spark:  =sparklyr::ml_logistic_regression()=
  - keras:  =parsnip::keras_mlp()=

*ハイパーパラメタ*
- =penalty=
  - 正則化の程度を決める非負の数値 (={glmnet}=, ={keras}=, ={spark}= で有効)
  - lambda に相当
  - stats::glm() などでは、0 にする
- =mixture=
  - 0-1 の数値 (={glmnet}=, ={spark}= で有効)
  - ElasticNet の alpha に相当? (Lasso = L1 の比率で指定)
  - 1 = Lasso, 0 = Ridge, 0 ~ 1 = ElasticNet

その他
- 特徴量は、標準化されている必要がある

**** ~multinom_reg(mode = "classification", penalty = NULL, mixture = NULL)~.

- 多項ロジスティック回帰
- Engines
  - glmnet: =glmnet::glmnet()= (default)
  - spark:  =sparklyr::ml_logistic_regression()=
  - keras:  =parsnip::keras_mlp()=

**** ~null_model(mode = "classification")~.
*** mode = "regression"
**** ~linear_reg(mode = "regression", penalty = NULL, mixture = NULL)~.

- 対応エンジン
  • "lm":    =stats::lm()= (default)
  - "glmnet" =glmnet::glmnet()=
  • "stan"   =rstanarm::stan_glm()=
  • "spark"  =sparklyr::ml_linear_regression()=
  • "keras"  =parsnip::keras_mlp()=


正則化ありの回帰
- Lasso = L1 正則化を行う回帰 (係数の絶対値に応じて罰則)
- Ridge = L2 正則化を行う回帰 (係数の二乗に応じて罰則)
- ElasticNet = L1 + L2 正則化
- 正則化の度合いを決めるパラメタ lambda (Complexity Paramter) がハイパーパラメタ

**** ~surv_reg(mode = "regression", dist = NULL)~.

- Parametric Survival Models
- Engines
  - "survival": =survival::survreg()= (default)
  - "flexsurv": =flexsurv::flexsurvreg()=

** ユーティリティ関数
*** =set_engine(object, engine, ...)=

- =...= でエンジン毎の個別の引数を渡すことができる
- 以下の関数を個別に使っても同じことが実現できる
  - =set_args(object, ...)=
  - =set_mode(object, mode)=
#+begin_src R
mod_xgb <- boost_tree(mode = "classification") %>%
  set_engine("xgboost", seed = 1999) %>%
  set_args(seed = 1998) %>%
  set_mode("regression")
mod_xgb
#+end_src

#+RESULTS:
: 
: Boosted Tree Model Specification (regression)
: 
: Engine-Specific Arguments:
:   seed = 1998
: 
: Computational engine: xgboost

** モデル作成のためのツール

#+begin_src R
set_new_model(model)

set_model_mode(model, mode)
set_model_engine(model, mode, eng)
set_model_arg(model, eng, parsnip, original, func, has_submodel)

set_dependency(model, eng, pkg)
get_dependency(model)

set_fit(model, mode, eng, value)
get_fit(model)

set_pred(model, mode, eng, type, value)
get_pred_type(model, type)

show_model_info(model)
pred_value_template(pre = NULL, post = NULL, func, ...)
#+end_src

* Vignette
** [[https://cloud.r-project.org/web/packages/parsnip/vignettes/parsnip_Intro.html][parsnip Basics]]

- ~model_spec~ class + 特定のモデル
- のちのち最適化されるパラメタは ~varying()~ として作成 (Placeholder の役割)
#+begin_src R
rf_mod <- rand_forest(trees =  2000, mtry = varying(), mode = "regression") %>%
  set_engine("ranger", seed = 63233)
rf_mod
class(rf_mod)
#+end_src

#+RESULTS:
#+begin_example
Random Forest Model Specification (regression)

Main Arguments:
  mtry = varying()
  trees = 2000

Engine-Specific Arguments:
  seed = 63233

Computational engine: ranger
[1] "rand_forest" "model_spec"
#+end_example

- モデルの当てはめを行うためには ~varying()~ のパラメタに具体的な値を入れる必要がある
- ~{ranger}~ を使う場合
#+begin_src R
rf_mod %>%
  set_args(mtry = 4) %>%
  set_engine("ranger") %>%
  fit(mpg ~ ., data = mtcars)
#+end_src

#+RESULTS:
#+begin_example
parsnip model object

Ranger result

Call:
 ranger::ranger(formula = formula, data = data, mtry = ~4, num.trees = ~2000,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) 

Type:                             Regression 
Number of trees:                  2000 
Sample size:                      32 
Number of independent variables:  10 
Mtry:                             4 
Target node size:                 5 
Variable importance mode:         none 
Splitrule:                        variance 
OOB prediction error (MSE):       5.49497 
R squared (OOB):                  0.8487239
#+end_example

- ~{randomForest}~ を使う場合
#+begin_src R
rf_mod %>%
  set_args(mtry = 4) %>%
  set_engine("randomForest") %>%
  fit(mpg ~ ., data = mtcars)
#+end_src

#+RESULTS:
#+begin_example
parsnip model object


Call:
 randomForest(x = as.data.frame(x), y = y, ntree = ~2000, mtry = ~4) 
               Type of random forest: regression
                     Number of trees: 2000
No. of variables tried at each split: 4

          Mean of squared residuals: 5.564976
                    % Var explained: 84.19
#+end_example

** [[https://tidymodels.github.io/parsnip/articles/articles/Scratch.html][Making a parsnip model from scratch]]
*** 概要

- ={parsnip}= では複数のモデルを 環境内の tibble で管理している
  - モデル名         = Engine + Mode(回帰 or 分類) を管理
  - モデル名+modes   = 対応している mode を管理
  - モデル名+pkgs    = Engine と package の対応を管理
  - モデル名+fit     = 当てはめの関数 + protect(いじれないパラメタ) + default
  - モデル名+args    = モデルのパラメタを管理 (dials で対応している関数など)
  - モデル名+predict = Engine, Mode, Type 毎の pre/post, func, args を管理
#+begin_src R
env <- get_model_env()
ls(env)
#+end_src

#+RESULTS:
#+begin_example
 [1] "boost_tree"               "boost_tree_args"         
 [3] "boost_tree_fit"           "boost_tree_modes"        
 [5] "boost_tree_pkgs"          "boost_tree_predict"      
 [7] "decision_tree"            "decision_tree_args"      
 [9] "decision_tree_fit"        "decision_tree_modes"     
[11] "decision_tree_pkgs"       "decision_tree_predict"   
[13] "linear_reg"               "linear_reg_args"         
[15] "linear_reg_fit"           "linear_reg_modes"        
[17] "linear_reg_pkgs"          "linear_reg_predict"      
[19] "logistic_reg"             "logistic_reg_args"       
[21] "logistic_reg_fit"         "logistic_reg_modes"      
[23] "logistic_reg_pkgs"        "logistic_reg_predict"    
[25] "mars"                     "mars_args"               
[27] "mars_fit"                 "mars_modes"              
[29] "mars_pkgs"                "mars_predict"            
[31] "mlp"                      "mlp_args"                
[33] "mlp_fit"                  "mlp_modes"               
[35] "mlp_pkgs"                 "mlp_predict"             
[37] "models"                   "modes"                   
[39] "multinom_reg"             "multinom_reg_args"       
[41] "multinom_reg_fit"         "multinom_reg_modes"      
[43] "multinom_reg_pkgs"        "multinom_reg_predict"    
[45] "nearest_neighbor"         "nearest_neighbor_args"   
[47] "nearest_neighbor_fit"     "nearest_neighbor_modes"  
[49] "nearest_neighbor_pkgs"    "nearest_neighbor_predict"
[51] "null_model"               "null_model_args"         
[53] "null_model_fit"           "null_model_modes"        
[55] "null_model_pkgs"          "null_model_predict"      
[57] "rand_forest"              "rand_forest_args"        
[59] "rand_forest_fit"          "rand_forest_modes"       
[61] "rand_forest_pkgs"         "rand_forest_predict"     
[63] "surv_reg"                 "surv_reg_args"           
[65] "surv_reg_fit"             "surv_reg_modes"          
[67] "surv_reg_pkgs"            "surv_reg_predict"        
[69] "svm_poly"                 "svm_poly_args"           
[71] "svm_poly_fit"             "svm_poly_modes"          
[73] "svm_poly_pkgs"            "svm_poly_predict"        
[75] "svm_rbf"                  "svm_rbf_args"            
[77] "svm_rbf_fit"              "svm_rbf_modes"           
[79] "svm_rbf_pkgs"             "svm_rbf_predict"
#+end_example

*** 新規にモデルを登録

- 新たにモデルを作成
- 雛形となる tibble 群が作成される (中身はから)
#+begin_src R
set_new_model("mixture_da")
ls(env) %>% str_subset("mixture_da")
#+end_src

#+RESULTS:
: Error: Model `mixture_da` already exists
: [1] "mixture_da"         "mixture_da_args"    "mixture_da_fit"    
: [4] "mixture_da_modes"   "mixture_da_pkgs"    "mixture_da_predict"

- mode を追加
#+begin_src R
set_model_mode(model = "mixture_da", mode = "classification")
env$mixture_da_modes
#+end_src

#+RESULTS:
: [1] "unknown"        "classification"

- エンジンを追加
#+begin_src R :results value
set_model_engine(
  "mixture_da",
  mode = "classification",
  eng = "mda"
)
env$mixture_da
#+end_src

#+RESULTS:
| engine | mode           |
|--------+----------------|
| mda    | classification |

*** 引数を追加

- parsnip 内の用語と 元パッケージの用語の対応関係を記述
#+begin_src R
set_model_arg(
  model = "mixture_da",
  eng = "mda",
  parsnip = "sub_classes",
  original = "subclasses",
  func = list(pkg = "foo", fun = "bar"),
  has_submodel = FALSE
)
#+end_src

*** モデル関数を定義

- データの定義を decouple しているので、シンプル
- 実質入力のチェックとクラスの付与しかしていない
#+begin_src R
mixture_da <- function(mode = "classification", sub_classes = NULL) {
  ## Check for correct mode
  if (mode  != "classification") {
    stop("`mode` should be 'classification'", call. = FALSE)
  }

  ## Capture the arguments in quosures
  args <- list(sub_classes = rlang::enquo(sub_classes))

  # Save some empty slots for future parts of the specification
  out <- list(args = args, eng_args = NULL,
              mode = mode, method = NULL, engine = NULL)
  ## set classes in the correct order
  class(out) <- make_classes("mixture_da")
  out
}
#+end_src

*** fit 関数

- =interface=: "formula", "data.frame", "matrix" のいずれか
  - package 毎に必要なデータ形式を指定
- =protect=: ユーザーからは変更できないパラメタ
- =fun=: 関数名
- =defulat=: デフォルトの引数
#+begin_src R
set_fit(
  model = "mixture_da",
  eng = "mda",
  mode = "classification",
  value = list(
    interface = "formula",
    protect = c("formula", "data"),
    func = c(pkg = "mda", fun = "mda"),
    defaults = list()
  )
)
#+end_src

#+RESULTS:

*** predict 関数

- =pre= / =post=: カスタム関数を指定
- =func=: 予測関数 (S3 predict を指定するだけで OK なケースがおおい)
- =args=: predict 関数への引数 =expr()= でラップする
- 出力は分類の場合、文字列 or factor にする (data と同じ水準の factor に変換される)

- "class" で出力するモジュール
#+begin_src R :results silent
class_info <- list(
  pre = NULL,
  post = NULL,
  func = c(fun = "predict"),
  # These lists should be of the form:
  # {predict.mda argument name} = {values provided from parsnip objects}
  args = list(
    # We don't want the first two arguments evaluated right now
    # since they don't exist yet. `type` is a simple object that
    # doesn't need to have its evaluation deferred. 
    object = quote(object$fit),
    newdata = quote(new_data),
    type = "class"
  )
)

set_pred(
  model = "mixture_da",
  eng = "mda",
  mode = "classification",
  type = "class",
  value = class_info
)
#+end_src

- "prob" モジュール
#+begin_src R :results silent
prob_info <- pred_value_template(
  post = function(x, object) {
    tibble::as_tibble(x)
  },
  func = c(fun = "predict"),
  # Now everything else is put into the `args` slot
  object = quote(object$fit),
  newdata = quote(new_data),
  type = "posterior"
)

set_pred(
  model = "mixture_da",
  eng = "mda",
  mode = "classification",
  type = "prob",
  value = prob_info
)
#+end_src

*** 登録内容の確認

#+begin_src R
show_model_info("mixture_da")
#+end_src

#+RESULTS:
#+begin_example
Information for `mixture_da`
 modes: unknown, classification 

 engines: 
   classification: mda

 arguments: 
   mda: 
      sub_classes --
subclasses

 fit modules:
 engine           mode
    mda classification

 prediction modules:
             mode engine     methods
   classification    mda class, prob
#+end_example

*** 動作確認

- fit
#+begin_src R
set.seed(4622)
iris_split <- initial_split(iris, prop = 0.95)
iris_train <- training(iris_split)
iris_test  <-  testing(iris_split)

mda_spec <- mixture_da(sub_classes = 2) %>%
  set_engine("mda")

mda_fit <- mda_spec %>%
  fit(Species ~ ., data = iris_train, engine = "mda")
mda_fit
#+end_src

#+RESULTS:
#+begin_example
parsnip model object

Fit time:  24ms 
Call:
mda::mda(formula = formula, data = data, subclasses = ~2)

Dimension: 4 

Percent Between-Group Variance Explained:
    v1     v2     v3     v4 
 97.76  99.38 100.00 100.00 

Degrees of Freedom (per dimension): 5 

Training Misclassification Error: 0.02098 ( N = 143 )

Deviance: 11.62
#+end_example

- predict
#+begin_src R :results value
predict(mda_fit, new_data = iris_test, type = "prob") %>%
  mutate(Species = iris_test$Species) %>%
  head()
#+end_src

#+RESULTS:
|         .pred_setosa |     .pred_versicolor |      .pred_virginica | Species    |
|----------------------+----------------------+----------------------+------------|
|                    1 | 1.72337760601439e-28 | 1.09107367367995e-57 | setosa     |
| 1.43501532903074e-24 |    0.999999960731792 | 3.92682075131374e-08 | versicolor |
| 1.34812175451261e-24 |    0.999999376684472 |  6.2331552837483e-07 | versicolor |
| 7.30221560197495e-18 |    0.999999999993661 | 6.33879520989424e-12 | versicolor |
| 8.59022682250584e-56 | 0.000122526231580582 |    0.999877473768419 | virginica  |
| 8.46040420765578e-80 | 9.71025008037381e-11 |    0.999999999902897 | virginica  |

#+begin_src R :results value
predict(mda_fit, new_data = iris_test) %>%
  mutate(Species = iris_test$Species) %>%
  head()
#+end_src

#+RESULTS:
| .pred_class | Species    |
|-------------+------------|
| setosa      | setosa     |
| versicolor  | versicolor |
| versicolor  | versicolor |
| versicolor  | versicolor |
| virginica   | virginica  |
| virginica   | virginica  |

* iris: 線形回帰 vs. ランダムフォレスト

#+begin_src R
# 訓練データとテストデータに分割
splits <- initial_split(iris, prop = 0.8)

# 対数変換するレシピを作成
rec <- recipe(Sepal.Width ~ ., data =  iris) %>%
  step_log(all_numeric())
rec_trained <- rec %>% prep()
train_baked <- rec_trained %>% bake(new_data = training(splits))
test_baked <- rec_trained %>% bake(new_data = testing(splits))

# "lm" を engine として利用
lm_mod <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Sepal.Width ~ Sepal.Length, data = train_baked)
lm_mod
#+end_src

#+RESULTS:
: parsnip model object
: 
: 
: Call:
: stats::lm(formula = formula, data = data)
: 
: Coefficients:
:  (Intercept)  Sepal.Length  
:      1.22309      -0.06394

#+begin_src R
# predict() 予測生成
# テストデータと予測を結合
pred <- test_baked %>% bind_cols(predict(lm_mod, new_data = .))

# yardstick で予測精度指標を取得
metrics(pred, Sepal.Width, .pred)
#+end_src

#+RESULTS:
: # A tibble: 3 x 3
:   .metric .estimator .estimate
:   <chr>   <chr>          <dbl>
: 1 rmse    standard       0.141
: 2 rsq     standard       0.101
: 3 mae     standard       0.113
\\

- ランダムフォレスト
#+begin_src R
rf_mod <- rand_forest(trees =  2000, mtry = 1, mode = "regression") %>%
  set_engine("ranger", seed = 63233) %>%
  fit(Sepal.Width ~ Sepal.Length, data = train_baked)
rf_mod
#+end_src

#+RESULTS:
#+begin_example
parsnip model object

Ranger result

Call:
 ranger::ranger(formula = formula, data = data, mtry = ~1, num.trees = ~2000,      seed = ~63233, num.threads = 1, verbose = FALSE) 

Type:                             Regression 
Number of trees:                  2000 
Sample size:                      121 
Number of independent variables:  1 
Mtry:                             1 
Target node size:                 5 
Variable importance mode:         none 
Splitrule:                        variance 
OOB prediction error (MSE):       0.02354428 
R squared (OOB):                  -0.1513539
#+end_example
\\

- 線形回帰よりも精度向上
#+begin_src R
rf_pred <- test_baked %>% bind_cols(predict(rf_mod, new_data = .))
metrics(rf_pred, Sepal.Width, .pred)
#+end_src

#+RESULTS:
: # A tibble: 3 x 3
:   .metric .estimator .estimate
:   <
:   <
:          <dbl>
: 1 rmse    standard      0.122 
: 2 rsq     standard      0.316 
: 3 mae     standard      0.0950
\\

* 実行環境

#+begin_src R :results output :exports both
sessionInfo()
#+end_src

#+RESULTS:
#+begin_example
R version 3.6.1 (2019-07-05)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] forcats_0.4.0   stringr_1.4.0   dplyr_0.8.3     purrr_0.3.2    
 [5] readr_1.3.1     tidyr_1.0.0     tibble_2.1.3    ggplot2_3.2.1  
 [9] tidyverse_1.2.1 parsnip_0.0.3.1

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.2       cellranger_1.1.0 pillar_1.4.2     compiler_3.6.1  
 [5] tools_3.6.1      zeallot_0.1.0    jsonlite_1.6     lubridate_1.7.4 
 [9] lifecycle_0.1.0  gtable_0.3.0     nlme_3.1-141     lattice_0.20-38 
[13] pkgconfig_2.0.3  rlang_0.4.0      cli_1.1.0        rstudioapi_0.10 
[17] haven_2.1.1      withr_2.1.2      xml2_1.2.2       httr_1.4.1      
[21] generics_0.0.2   vctrs_0.2.0      hms_0.5.1        grid_3.6.1      
[25] tidyselect_0.2.5 glue_1.3.1       R6_2.4.0         readxl_1.3.1    
[29] pacman_0.5.1     modelr_0.1.5     magrittr_1.5     backports_1.1.5 
[33] scales_1.0.0     rvest_0.3.4      assertthat_0.2.1 colorspace_1.4-1
[37] stringi_1.4.3    lazyeval_0.2.2   munsell_0.5.0    broom_0.5.2     
[41] crayon_1.3.4
#+end_example
\\

* 参考リンク

- [[https://tidymodels.github.io/parsnip/][公式サイト]]
- [[https://cloud.r-project.org/web/packages/parsnip/index.html][CRAN]]
- [[https://cloud.r-project.org/web/packages/parsnip/parsnip.pdf][Reference Manual]]
- [[https://github.com/tidymodels/parsnip][Github Repo]]
- [[https://tidymodels.github.io/parsnip/articles/articles/Models.html][List of Models]]

- Vignette
  - [[https://cloud.r-project.org/web/packages/parsnip/vignettes/parsnip_Intro.html][parsnip Basics]]
  - [[https://tidymodels.github.io/parsnip/articles/articles/Regression.html][Regression Example]]
  - [[https://tidymodels.github.io/parsnip/articles/articles/Classification.html][Classification Example]]
  - [[https://tidymodels.github.io/parsnip/articles/articles/Scratch.html][Making a parsnip model from scratch]]
  - [[https://tidymodels.github.io/parsnip/articles/articles/Submodels.html][Evaluating Submodels with the Same Model Object]]

- [[https://tidymodels.github.io/model-implementation-principles/][Conventions for R Modeling Packages]]

- Blog
  - [[https://speakerdeck.com/s_uryu/tidymodels][tidymodelsによるモデル構築と運用@speakerdeck]]
  - [[https://dropout009.hatenablog.com/entry/2019/01/06/124932][tidymodelsによるtidyな機械学習フロー（その1）@Dropout]]
  - [[https://dropout009.hatenablog.com/entry/2019/01/09/214233][tidymodelsによるtidyな機械学習フロー（その2：Cross Varidation）@Dropout]]
  - [[https://dropout009.hatenablog.com/entry/2019/11/10/125650][tidymodelsによるtidyな機械学習（その3：ハイパーパラメータのチューニング）@Dropout]]
  - [[https://dropout009.hatenablog.com/entry/2019/11/17/112655][tidymodelsとDALEXによるtidyで解釈可能な機械学習@Dropout]]

#+STARTUP: folded indent inlineimages latexpreview
#+PROPERTY: header-args:R :session *R:bayesian* :width 640 :height 480 :results output

* ベイズ統計学

- 統計モデルを推定するためのツール (ベイズ統計自体が「統計モデル」なのではない)
- 全てのパラメタを確率変数とみなして、確率分布を想定する
  - パラメタが 2 とか 3 になる、ということがわかるのではなく確率分布としてわかる
- 実際に得られたデータで、もともとの想定 (事前分布) を更新して事後分布とする (ベイズ更新)
  - データから得られた知見を事後分布として表現する

_伝統的な統計学に対してのメリット_

1. 解釈が容易
  - 伝統的な統計学では、最尤推定されるのは一点 (点推定) なのに対して、ベイズではパラメタの分布で得られる
  - そのため、仮説検定や信頼区間の解釈が直感的でわかりやすい

2. 伝統的な統計学では最尤推定が難しい
  - 複雑なモデルでは、最尤推定が難しくなる
  - 局所最適解に陥る場合がある

3. 過学習に陥りにくい

* ベイズの定理

- トーマス・ベイズ (1702-1761)
- リチャード・プライスにより世に出される (1763)
- ラプラスが近代数学としての形式にまとめる
- 条件付き確率の関係を整理したもの

以下のどちらも、成り立つ (乗法定理の対称性)
$P(\theta, X) = P(\theta|X)P(X)$
$P(\theta, X) = P(X|\theta)P(\theta)$

このとき
$P(\theta)$     事前確率 = 事象 X が起きる前の確率
$P(X|\theta)$  尤度 = $\theta$ がおきた時の X が起きる確率
$P(\theta|X)$  事後確率 = 事象 X が起きた後の $\theta$ の確率

よって、2つの式をつないで、$P(X)$ でわると
$\frac{P(\theta|X)P(X)}{P(X)} = \frac{P(X|\theta)P(\theta)}{P(X)}$

したがって
$P(\theta|X) = \frac{P(X|\theta) P(\theta)}{P(X)}$
  
- $\frac{P(X|\theta)}{P(X)}$ が事前確率を更新(ベイス更新)するための修正項 (データの得られやすさの分だけ事後確率を更新する)

この点をわかりやすくするため、以下のようにも書く

$P(\theta|X) = \frac{P(X|\theta)}{P(X)} P(\theta)$


-  $P(X)$ は実際に得られたデータのみに依存し、$\theta$ に影響しない定数項であるため、以下のようにも書く
 (正規化定数とみなす)

$P(\theta|X) \propto P(X|\theta)P(\theta)$

Stan はこの考え方で、パラメタの乱数を生成する

* 例

- 病気 A は 1 万人辺り 40 人の割合でかかる
- 病気 A にかかっている人が、検診 B を受けると 8 割が陽性になる
- 病気 A にかかっていない人が、検診 B を受けると 9 割が陰性になる
- 検診 B によって陽性と判断された人が、病気 A にかかっている確率は？

|             | Positive B1      | Negative B2      | Total      |
|-------------+------------------+------------------+------------|
| Sick A1     | 40/10000 * 0.8   | 40/10000 * 0.2   | 40/10000   |
| Not Sick A2 | 9960/10000 * 0.1 | 9960/10000 * 0.9 | 9960/10000 |


$P(A1|B1)=\frac{P(B1|A1)P(A1)}{P(B1|A1)P(A1)+P(B1|A2)P(A2)}$

$P(A1|B1)=\frac{0.8 \times 0.004}{0.8 \times 0.004 + 0.1 \times 0.996} = 0.0311$

- P(B1|A1) 病気 A の人が陽性になる確率(0.8) = 尤度
- P(A1)    病気 A になる確率(0.004) = 事前確率
- P(B1|A2) 病気 A でない人が陽性になる確率(0.1) = 尤度
- P(A2)    病気 A にならない確率(0.996) = 事前確率

* ベイズ推定
* ベイズの指標・用語

$\theta_{eap}^* = \int{\theta f(\theta|x)d\theta}$

- 複雑な式だと積分が難しい
- 乱数からのサンプルを得る
  - 平均値を *EAP 推定量*
  - 最頻値を *MAP 推定量*
  - 中央値を *MED 推定量*

* 参考

- [[https://www.slideshare.net/matsukenbook/15-59154892][15分でわかる(範囲の)ベイズ統計学@SlideShare]]

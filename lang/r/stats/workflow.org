#+STARTUP: folded indent inlineimages latexpreview
#+PROPERTY: header-args:R :session *R:workflows* :width 640 :height 480 :results output

* ライブラリの読み込み
  
#+begin_src R :results silent
library(tidyverse)
library(tidymodels)
#+end_src

* General workflow

- データの前処理
  - *raw* _"生データの用意"_
    - データの読み込み
    - 訓練データとテストデータの結合
    - 明らかなデータエラーを修正する
  - *base* _"特徴量の意味に即した型に変換する"_
    - ラベル
      - 回帰: numeric
      - 分類: factor
    - 特徴量
      - サポートされる型: double, integer, factor, ordered, logical
    - 欠損値の補完

- 訓練データとテストデータに分割
  - パラメタチューニングのための Resample と最終的なスコアを算出する Resample の seed を分ける

- EDA
  - ラベルと特徴量の関係を可視化
  - 変数間の関係を可視化
    - 相関行列
    - 単純な決定木系のモデルを作成して、特徴量重要度を把握する
    - Lasso で削減される変数を把握する

- ベースラインモデルを作成
  - *base* 特徴量と一般的なパラメタを使って、モデル毎のベンチマークとなるスコアを算出する

- 特徴量の作成
  - *feats01 ~ featsN*
    - 新たな特徴量の追加
    - 追加のみを行ってバージョン管理をする
  - *feats01s~ featsNs*
    - 特徴量の取捨選択

- パラメタと前処理手法のチューニング
  - パラメタセット x 前処理 (エンコーディング手法等) のスコアを算出

- 予測のアンサンブル・スタッキング

* ={tidymodels}= を使った機械学習ワークフロー

1. データの分割 ={rsample}=
   - 訓練データとテストデータ
   - クロスバリデーション用の分割

2. データの前処理・特徴量抽出 ={recipes}= + ={tune}=
   - =recipe()= -> =step_*()=
   - 前処理だけでなく、モデルの構造(目的変数 ~ 説明変数)も指定する
   - =step_*()= の中でチューニングすべきパラメタは =tune()= を指定する
   - prep() 以降は行わず =tune::tune()= にレシピを渡す

3. モデルの作成 ={parsnip}= + ={tune}=
   - モデル指定 + エンジン指定 + ハイパーパラメタを =tune()= 指定

4. パラメタグリッドの用意 ={dials}=
   - モデルに必要なハイパーパラメタに応じて作成
   - grid サーチ or その他の手法を選択

5. 当てはめ実行 ={tune}=
   - これまでに作成した、データ・レシピ・モデル・パラメタを渡す. =tune::tune_grid()=
   - パラメタ範囲からベストモデルを選択する

6. ベストモデルでの再学習と予測 ={tune}= + ={stats}=
   - =tune::select_best()= でベストのパラメタを抽出
   - =stats::update()= でモデル更新 + =parsnip::predict.model_fit()= で予測生成

7. (評価指標に合わせた予測データの後処理)
   - ={workflows}= リリース後にできるようになる模様
   - 分類確率の閾値を探索する等

* TODOs [0/1]
** TODO ={workflows}= が開発されたら置き換える


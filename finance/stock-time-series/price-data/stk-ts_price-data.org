#+STARTUP: folded indent inlineimages
#+PROPERTY: header-args:R :results output :exports both :colnames yes
#+PROPERTY: header-args:R+ :session *R:price-data* :width 640 :height 480 :eval never-export
#+OPTIONS: author:nil H:6 toc:nil
#+HUGO_BASE_DIR: ~/Dropbox/repos/github/five-dots/blog
#+HUGO_SECTION: post/2019/12/

#+TITLE: [R と Stan で株式時系列分析シリーズ] 株価データの入手
#+DATE: 2019-12-05
#+HUGO_CATEGORIES: finance
#+HUGO_TAGS: r etf stock series
#+HUGO_CUSTOM_FRONT_MATTER: :toc false

それではまず、株価データをダウンロードすることから始めてみよう。本シリーズでは、一貫して米国株式の *セクター ETF* を利用して分析を進めていく。ここでは、R の ={tidyquant}= パッケージを利用して、データを入手する方法を紹介する。

* 株式セクター ETF

セクターと呼ばれる産業単位で投資対象を限定した ETF を *セクター ETF* と呼ぶ。セクターの分類方法にはいくつかの種類があるが、ここでは [[https://www.msci.com/gics][GICS Sector]] の分類に従った [[http://www.sectorspdr.com/sectorspdr/][Select Sector SPDR ETFs]] シリーズの ETF を利用しよう。他にも Vanguard が提供するものなどがあるが、SPDR シリーズが最も古くから上場されており、セクター ETF といえば、この *"X"* から始まる SPDR ETF シリーズだろう。

現在 11 のセクターに分類されているが、XLRE と XLC は近年追加されたもので、長期の分析ができないため、今回は除外し、計 9 セクターを分析対象とする。 

| シンボル | セクター (英)          | セクター (日)                | 主要銘柄        |
|----------+------------------------+------------------------------+-----------------|
| XLB      | Materials              | 素材                         | LIN, DD, ECL    |
| XLE      | Energy                 | エネルギー                   | XOM, CVX, COP   |
| XLF      | Finance                | 金融                         | BRK.B, JPM, BAC |
| XLI      | Industrial             | 資本財                       | BA, HON, UNP    |
| XLK      | Technology             | テクノロジー                 | MSFT, AAPL, V   |
| XLP      | Consumer Staples       | 生活必需品                   | PG, KO, PEP     |
| XLU      | Utilities              | 公益事業                     | NEE, DUK, D     |
| XLV      | Health                 | ヘルスケア                   | JNJ, PFE, UNH   |
| XLY      | Consumer Discretionary | 一般消費財                   | AMZN, HD, MCD   |
| +XLRE+     | Real Estate            | 不動産                       | AMT, CCI, PLD   |
| +XLC+      | Communication Service  | コミュニケーション・サービス | FB, GOOG, DIS   |

分析対象としてセクター ETF を選択したのは、以下の理由からだ。
- 9 セクター全てで 20 年以上の長期のデータが利用可能
- 相関関係の分析対象として最適 (セクター A が下落したら、セクター B は上昇する等)
- 先行研究が豊富
- 最終的にセクターローテーション戦略の開発を目指す

[参考] 上場開始日
- XLRE: 2015/10/08 から取引開始
- XLC: 2018/11/03 から取引開始
- その他: 1998/12/22 から取引開始

* R ライブラリ

R でのダウンロード方法の解説に移ろう。今回は [[https://cran.r-project.org/web/packages/tidyquant/index.html][ ={tidyquant}= ]]パッケージを利用して [[https://finance.yahoo.com/][Yahoo Finance]] からデータを取得する。 ={tidyquant}= は [[https://id.fnshr.info/2017/01/09/tidy-data-intro/][整然データ (Tidy Data)]] の =data.frame= として株価をダウンロードしてくれるので ={tidyverse}= のパッケージ群との連携に便利だ。

R から Yahoo Finance のデータを読み込む際には、一般的に、[[https://github.com/joshuaulrich/quantmod][ ={quantmod}= ]]が利用されることが多い。しかし ={quantmod}= では、 =xts= でデータが取得されるため ={ggplot2}= や ={dplyr}= を利用するためには =data.frame= 変換を挟む必要がある。

個人的には、データは =data.frame= (=tibble含む=) に統一しておき、必要に応じて他の形式に変換する方針が最も効率的ではないかと考えている。

※ ={tidyquant}= は内部で ={quantmod}= の関数を呼び出しているので ={quantmod}= を利用しているのに違いはない。

それでは、実際にパッケージを読み込んでみよう。
#+begin_src R :results silent
## インストールしていなければ、以下を実行
## install.packages("tidyquant")
## install.packages("tidyverse")

library(tidyquant)
library(tidyverse) # 以降のデータ操作に利用
#+end_src

* データのダウンロード

データをダウンロードするコードは以下の通りだ。今後、データを表示する際に、セクター順を制御するために、セクター名を因子型 (=factor=) に変換している。また、比較対象として、S&P 500 指数の ETF である SPY も同時にダウンロードしよう。

#+begin_src R :results silent
## sectorの並び順を用意しておく
sector_levels <- c(
  "S&P 500", "Industrial", "Consumer Discretionary", "Technology",
  "Financials", "Health Care", "Materials",
  "Consumer Staples", "Energy", "Utilities")

## tibble::tribble() で銘柄リストを作成すると書きやすい
sector_etfs <- tribble(
  ~symbol, ~sector,
  "XLB",   "Materials",
  "XLE",   "Energy",
  "XLF",   "Financials",
  "XLI",   "Industrial",
  "XLK",   "Technology",
  "XLP",   "Consumer Staples",
  "XLU",   "Utilities",
  "XLV",   "Health Care",
  "XLY",   "Consumer Discretionary"
) %>%
  ## 因子型に変換
  mutate(sector = factor(sector, levels = sector_levels))

benchmark_etfs <- tribble(
  ~symbol, ~sector,
  "SPY",   "S&P 500"
) %>%
  ## 因子型に変換
  mutate(sector = factor(sector, levels = sector_levels))

## tidyquant::tq_get() で全ての銘柄をダウンロード
rawdata <- tq_get(c(sector_etfs$symbol, benchmark_etfs$symbol), from = "1998-12-22")
#+end_src

データは、典型的な四本値 + 分割・配当調整済みの終値 (adjusted) という構成だ。
#+begin_src R :results value
head(rawdata) %>% mutate_if(is.numeric, round, digits = 2) # 表示を見やすいように桁数を制限
#+end_src

#+RESULTS:
| symbol |       date |  open |  high |   low | close | volume | adjusted |
|--------+------------+-------+-------+-------+-------+--------+----------|
| XLB    | 1998-12-22 | 20.78 | 20.83 | 20.75 | 20.83 |   1900 |    13.04 |
| XLB    | 1998-12-23 | 20.97 | 21.14 | 20.97 | 21.05 |    700 |    13.18 |
| XLB    | 1998-12-24 |  21.3 | 21.53 |  21.2 | 21.53 |   1500 |    13.48 |
| XLB    | 1998-12-28 |  21.5 |  21.5 | 21.31 | 21.34 |   2500 |    13.36 |
| XLB    | 1998-12-29 | 21.73 | 21.73 | 21.73 | 21.73 |    100 |    13.61 |
| XLB    | 1998-12-30 | 21.72 | 21.72 | 21.67 | 21.67 |    800 |    13.57 |

全ての銘柄で欠損データなどがないか、データの件数を確認しておこう。
#+begin_src R :results value
rawdata %>%
  group_by(symbol) %>%
  summarize(
    start = min(date),
    end = max(date),
    count = n()
  )
#+end_src

#+RESULTS:
| symbol |      start |        end | count |
|--------+------------+------------+-------|
| SPY    | 1998-12-22 | 2019-12-04 |  5272 |
| XLB    | 1998-12-22 | 2019-12-04 |  5272 |
| XLE    | 1998-12-22 | 2019-12-04 |  5272 |
| XLF    | 1998-12-22 | 2019-12-04 |  5272 |
| XLI    | 1998-12-22 | 2019-12-04 |  5272 |
| XLK    | 1998-12-22 | 2019-12-04 |  5272 |
| XLP    | 1998-12-22 | 2019-12-04 |  5272 |
| XLU    | 1998-12-22 | 2019-12-04 |  5272 |
| XLV    | 1998-12-22 | 2019-12-04 |  5272 |
| XLY    | 1998-12-22 | 2019-12-04 |  5272 |

問題なくデータを入手できたようだ。

* Fama-French
* データの保存

以降の分析がすぐに始められるよう、環境を保存して今回は終了だ。
#+begin_comment
rm("settings")
save.image("us-etf-research.RData")
#+end_comment

#+begin_src R :results silent
save.image("price-data.RData")
#+end_src

* [参考] 米国株式の主な情報源の紹介

米国の株式は、さすが世界最大の株式市場というだけあり、様々な企業がデータ提供をおこなっている。また、それらのサービスの API を利用する R パッケージが公開されていることも多く、非常に便利にデータを取得できる。専用のパッケージになっていなくても、REST API が提供されていれば ={curl}= などを利用して、簡単に R から利用することが可能だ。

今回は、Yahoo Finance のデータを利用したが、ニーズに応じてサービスを選択できる。参考として、無償・有償含め、主だったものを下記にリストアップした。

| サービス      | 無償 | R パッケージ      | 備考                                  |
|---------------+------+-------------------+---------------------------------------|
| [[https://finance.yahoo.com/][Yahoo Finance]] | Yes  | [[https://cran.r-project.org/web/packages/quantmod/index.html][ ={quantmod}= ]]      | [[https://developer.yahoo.com/yql/guide/overview.html#usage-information-and-limits][制限 (2,000 req/hour)]]                 |
| [[https://www.alphavantage.co/][Alphavantage]]  | Yes  | [[https://cran.r-project.org/web/packages/alphavantager/index.html][ ={alphavantager}= ]] | [[https://www.alphavantage.co/premium/][制限 (5 req/min, 500 req/day)]]         |
| [[https://iexcloud.io/][IEX Cloud]]     | Yes  | [[https://cran.r-project.org/web/packages/Riex/index.html][ ={Riex}= ]]          | [[https://iexcloud.io/pricing/][料金表 (無料枠 500,000 message/month)]] |
| [[https://www.quandl.com/][Quandl]]        | No   | [[https://cran.r-project.org/web/packages/Quandl/index.html][ ={Quandl}= ]]        | [[https://www.quandl.com/data/EOD-End-of-Day-US-Stock-Prices][EOD]] や [[https://www.quandl.com/databases/SEP/data][SEP]] が米国株の日足データ       |
| [[https://iqfeed.net/][IQFeed]]        | No   | [[https://cran.r-project.org/web/packages/QuantTools/index.html][ ={QuanTools}= ]]     | リアルタイム/ティック/分足/日足       |
| [[https://polygon.io/][polygon.io]]    | No   | - (={curl}= + REST) | リアルタイム/ティック/分足/日足       |
| [[https://www.algoseek.com/][AlgoSeek]]      | No   | - (={curl}= + REST) | ティック/分足/日足                    |
| [[https://www.quantgo.com/][QuantGo]]       | No   | - (={curl}= + REST) | クラウドでのデータアクセス            |

** 有償サービスを検討すべきとき

もし、以下のようなニーズがあれば、有償のデータサービスを検討する必要が出てくるだろう。
1. 分足やティックデータ (日中足) など、日足よりも短い期間のヒストリカルデータ
   - ある程度の長さの日中足データは、ほぼ無償では入手できないと考えた方がよい
   - デイトレードや HFT の戦略を開発したい場合は、このタイプのデータが必要
2. リアルタイムデータ
   - 実際にリアルタイムでシグナルを生成し、発注を行う場合はこのタイプのデータが必要
3. 過去に上場停止になった銘柄を含むデータ
   - S&P 500 などのインデックスの構成銘柄に対して、長期のバックテストを行いたい場合で、[[https://ja.wikipedia.org/wiki/%E7%94%9F%E5%AD%98%E8%80%85%E3%83%90%E3%82%A4%E3%82%A2%E3%82%B9][生存者バイアス]]を避ける必要がある場合はこのタイプのデータが必要

私が利用した経験のある範囲では、1 と 2 のニーズには [[https://iqfeed.net/][IQFeed]] 、3 のニーズには、[[https://www.quandl.com/databases/SEP/data][Quandl の SEP]] が個人でも現実的なコストでアクセスできるので、良いのではないかと思う。

* COMMENT Local Variables                                           :ARCHIVE:
  # Local Variables:
  # eval: (org-hugo-auto-export-mode)
  # End:
